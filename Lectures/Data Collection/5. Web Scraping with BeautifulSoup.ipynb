{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfacfff1",
   "metadata": {},
   "source": [
    "# Web Scraping with BeautifulSoup\n",
    "\n",
    "Sometimes there may not be an easily accessible data set for the project you are interested. However, there may be data that exists on the web which you can scrape. One way to do this in python is to use `BeautifulSoup`.\n",
    "\n",
    "## What we will accomplish in this notebook\n",
    "\n",
    "In this notebook we will:\n",
    "- Discuss the structure of HTML code,\n",
    "- Introduce the `bs4` pacakge,\n",
    "- Parse simple HTML code with `BeautifulSoup`,\n",
    "- Review how to request the HTML code from a url,\n",
    "- Scrape data from an actual webpage and\n",
    "- Touch on some of the issues that may arise when web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import base packages we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from seaborn import set_style\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9779c",
   "metadata": {},
   "source": [
    "## Scraping data with `BeautifulSoup`\n",
    "\n",
    "### Importing `BeautifulSoup`\n",
    "\n",
    "In order to use `BeautifulSoup` we first need to make sure that we have it installed on our computer. Try to run the following code chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82194053",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this imports BeautifulSoup from its package, bs4\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f61184",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this to check your version\n",
    "## I wrote this notebook with version  4.10.0\n",
    "print(bs4.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2da4d",
   "metadata": {},
   "source": [
    "If the above code does not work you will need to install the package before being able to run the code in this notebook. Here are installation instructions from the `bs4` documentation:\n",
    "- Via conda: <a href=\"https://anaconda.org/conda-forge/bs4\">https://anaconda.org/conda-forge/bs4</a>,\n",
    "- Via pip: <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup\">https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83239b6",
   "metadata": {},
   "source": [
    "### The structure of an HTML page\n",
    "\n",
    "`BeautifulSoup` takes in an HTML document and will 'parse' it for you so that you can extract the information you want. To best understand what that means we will look at a toy example of a webpage. To see what the snippet of HTML code below looks like in a web browser click here <a href=\"SampleHTML.html\">SampleHTML.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is an html chunk\n",
    "## It has a head and a body, just like you\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f371b5",
   "metadata": {},
   "source": [
    "We can now use `BeautifulSoup` to parse this simple HTML chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we import the BeautifulSoup object\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we make a BeautifulSoup object out of the html code\n",
    "## The first input is the html code\n",
    "## The second input is how you want BeautifulSoup\n",
    "## to parse the code\n",
    "soup = BeautifulSoup(html_doc,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use the prettify method to make our html pretty and see what it has to say\n",
    "## Ideally this is how someone writing pure html code would write their code\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52dcc37",
   "metadata": {},
   "source": [
    "Html files have a natural tree structure that we will briefly cover now. Here is the tree of our sample HTML:\n",
    "\n",
    "<img src = \"html_tree.png\" width = \"50%\"></img>\n",
    "\n",
    "Each level in the tree represents a 'generation' of the html code. for instance the body has 3 p children, the leftmost p has one b child. `BeautifulSoup` helps us traverse these trees to gather the data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below are some examples of beautifulsoup methods and \n",
    "## attributes that help us better understand the structure \n",
    "## of html code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can traverse to the \"title\" by working our way through\n",
    "## the tree\n",
    "print(soup.head.title)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notice we can also get the title like so\n",
    "## This is because this is the first and only title \n",
    "## in the code\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What if I just want the text from the title?\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What html structure is the title's parent?\n",
    "print(soup.title.parent)\n",
    "print(soup.title.parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c2df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the first a of the html document?\n",
    "print(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e49026",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the first a's class?\n",
    "print(soup.a['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are multiple a's can I find all of them?\n",
    "print(soup.find_all('a'))\n",
    "\n",
    "\n",
    "for a in soup.find_all('a'):\n",
    "    print()\n",
    "    print(a['class'], a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf7b99",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "Take a moment and try to complete the following exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the first p of the document\n",
    "## What is the first p's class? What string is in that p?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54200461",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For all of the a's in the document find their href\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a406bf7",
   "metadata": {},
   "source": [
    "## Scraping real webpages\n",
    "\n",
    "Let's now pivot to a real webpage. In this example we will imagine we are in the spot of wanting to scrape information regarding the website FiveThirtyEight's Sports articles as found here, <a href=\"https://fivethirtyeight.com/sports/\">https://fivethirtyeight.com/sports/</a>.\n",
    "\n",
    "### Sending a request\n",
    "\n",
    "In order to scrape that data we need to have the HTML code associated with the page. In python we can do this with the `requests` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5254c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081861fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the url for the HTML code we want\n",
    "url = \"https://fivethirtyeight.com/sports/\"\n",
    "\n",
    "## We send a request to the website's server with\n",
    "## the following code\n",
    "requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b6285",
   "metadata": {},
   "source": [
    "Now we will want to store this response in a variable so we can access its contents. First we will note that, if the request was successful, we should be seeing `<Response [200]>` above. This tells us that the request was recieved and the data was returned successfully. If we instead saw something like `404` or `500`, we would know that something went wrong. For a list of possible response codes see <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses\">https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d357ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b318c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The HTML code is stored in r.content\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can now parse this data with BeautifulSoup\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106d4aa",
   "metadata": {},
   "source": [
    "### Web developer tools\n",
    "\n",
    "As we can see, this is much messier than our simple example above. \n",
    "\n",
    "We only want three pieces of information for each article/podcast/posting listed on the page:\n",
    "1. The title,\n",
    "2. The author and\n",
    "3. The associated url.\n",
    "\n",
    "To hone in on this information we can utilize the web developer tools for your browser. Below are links on how to locate the web developer tools for Mozilla Firefox, Google Chrome and Safari:\n",
    "- Mozilla Firefox: Go to `Browser Tools` in the `Tools` dropdown menu and click on `Web Developer Tools` you should see something like this:\n",
    "<img src=\"firefox_develop.jpg\" width=\"80%\"></img>\n",
    "- Google Chrome: Go to `Developer` in the `View` dropdown menu and click on `Developer Tools` you should see something like this:\n",
    "<img src=\"chrome_develop.jpg\" width=\"80%\"></img>\n",
    "- Safari: Go to the `Develop` dropdown menu and select `Show Web Inspector`, if there is no `Develop` dropdown menu follow the instructions on this page <a href=\"https://support.apple.com/guide/safari/use-the-developer-tools-in-the-develop-menu-sfri20948/mac\">https://support.apple.com/guide/safari/use-the-developer-tools-in-the-develop-menu-sfri20948/mac</a>. You should see something like this once opened:\n",
    "<img src=\"safari_develop.jpg\" width=\"80%\"></img>\n",
    "\n",
    "<i>Note that the images above will be slightly different than what you see because 538 will have different articles at the time you access the page. These images were added 3-10-2022.</i>\n",
    "\n",
    "<br>\n",
    "\n",
    "The web developer tools will allow you to find out in what HTML elements certain pieces of data live. For example, you should be able to hover over an item on the webpage and it will highlight what HTML structure holds it. Here we can see what that looks like for the banner article (the large one at the top) of this page:\n",
    "<img src=\"div_highlight.png\" width=\"30%\"></img>\n",
    "\n",
    "So the article title and author are stored in a `div` item with the `class` `post.info`. We can use the `soup`'s `find` and `find_all` functionality to get the data we desire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edfc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "## .find takes in an HTML element type\n",
    "## and a dictionary that specifies additional qualifications you\n",
    "## want the element to have\n",
    "## and returns the first such element in the HTML code that\n",
    "## meets the desired requirements.\n",
    "##############\n",
    "##############\n",
    "## First we'll find the id=primary div, then within that the class=post-info div\n",
    "soup.find('div', {'class':\"post-info\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef270c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## .find_all follows the same syntax as .find,\n",
    "## but returns all HTML elements that satisfy the\n",
    "## requirements you provide\n",
    "##############\n",
    "##############\n",
    "## First we'll find the id=primary div, then within that the class=post-info div\n",
    "soup.find_all('div', {'class':\"post-info\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's get the title for the fist post\n",
    "soup.find('div', {'class':\"post-info\"}).find('h2', {'class':\"article-title entry-title\"}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccb339",
   "metadata": {},
   "source": [
    "Now we can write a loop that finds all of the titles for articles contained in `div`s with `class=\"post-info\"` using `find_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use find_all\n",
    "for div in soup.find_all('div', {'class':\"post-info\"}):\n",
    "    ## it's good practice to check that the element you're expecting\n",
    "    ## to be there is actually there before \n",
    "    if div.find('h2', {'class':\"article-title entry-title\"}):\n",
    "        ## I clean the text here to remove annoying white space\n",
    "        print(div.find('h2', {'class':\"article-title entry-title\"}).text.replace(\"\\n\", \" \").strip())\n",
    "    elif div.find('h3', {'class':\"article-title entry-title\"}):\n",
    "        print(div.find('h3', {'class':\"article-title entry-title\"}).text.replace(\"\\n\", \" \").strip())\n",
    "    else:\n",
    "        print(\"Title not in h2 or h3 elements\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc15c4",
   "metadata": {},
   "source": [
    "Here we can notice one of the difficulties in web scraping, messiness of HTML code. \n",
    "\n",
    "At the end of our titles we might notice a few repeats this is due to 538's \"Top Sports Stories Today\" section in the bottom right of the page. These titles are also stored in a `div` with `class=\"post-info\"`. While this does not result in a messy webpage, it does make our task slightly more complicated.\n",
    "\n",
    "It helps to notice that the `div`s of articles that are not the banner article are themselves contained within a `div` with `class=\"posts content-area\"`. We can thus first `find` that `div` and then `find_all` `post-info` `div`s within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use find_all\n",
    "for div in soup.find('div', {'class':\"posts content-area\"}).find_all('div', {'class':\"post-info\"}):\n",
    "    ## it's good practice to check that the element you're expecting\n",
    "    ## to be there is actually there before \n",
    "    if div.find('h2', {'class':\"article-title entry-title\"}):\n",
    "        ## I clean the text here to remove annoying white space\n",
    "        print(div.find('h2', {'class':\"article-title entry-title\"}).text.replace(\"\\n\", \" \").strip())\n",
    "    elif div.find('h3', {'class':\"article-title entry-title\"}):\n",
    "        print(div.find('h3', {'class':\"article-title entry-title\"}).text.replace(\"\\n\", \" \").strip())\n",
    "    else:\n",
    "        print(\"Title not in h2 or h3 elements\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea7fd0",
   "metadata": {},
   "source": [
    "We now have code to get all of the article titles on the page including both the banner article and the list of articles beneath.\n",
    "\n",
    "##### Exercise\n",
    "\n",
    "Take some time to write code to retrieve all of the article authors and article URLs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### URLS ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c718d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### authors ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda13f8",
   "metadata": {},
   "source": [
    "## Common problems while web scraping\n",
    "\n",
    "### Messy or inconsistent HTML code\n",
    "\n",
    "We have seen one problem that you can encounter while web scraping, small and messy differences in HTML code that make automating your scraping more difficult. It is important to note that 538 is actually not very messy in the grand scheme of the world wide web. For example, you can come across websites that do not label their HTML elements with `id`s or `class`es or any other kind of distinguishing meta data. This makes automation incredibly difficult. Other websites may offer no consistency from page to page. In such cases there may not be a quick or easy fix, you typically just have to hack something together and hope it works.\n",
    "\n",
    "### Too many requests\n",
    "\n",
    "Repeatedly sending requests to the same website can raise a flag at the site's server after which your IP address will be blocked from receiving future request results for some period of time. This is why it is good practice to space out your requests to a single website. You can do so with the `sleep` function in the `time` module, <a href=\"https://docs.python.org/3/library/time.html#time.sleep\">https://docs.python.org/3/library/time.html#time.sleep</a>. While this decreases your risk of being flagged as a bot/scraper, it is also just being a good denizen of the internet. Sending too many requests to a single website in a short amount of time can mess with that website's ability to function for other visitors.\n",
    "\n",
    "### Bot detection\n",
    "\n",
    "Some websites have been set up to detect bot/scraper activity regardless of the number of times you send a request. Sometimes there are ways around this, but the specific approach depends upon how the website is blocking your request. To counter such detection do a web search for the specific error or response code you are getting and look for a helpful stack overflow or stackexchange post.\n",
    "\n",
    "### User interactive content\n",
    "\n",
    "Some of the content on a page may be dependent on the actions of a user visiting that page. For example, there are websites where data tables do not load until the user has clicked a button or scrolled down the page. Again there are work arounds to this, but the answer will depend upon the specific issue you are encountering. Do a web search and there is likely to be a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b52dbb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we touched on how you can parse HTML code with the `bs4` package. We looked at both a simple phony example and an example from a live website. If you are interested in learning more about `bs4` I encourage you to consult their documentation, <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e3780",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed0b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
