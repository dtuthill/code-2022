{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15651843",
   "metadata": {},
   "source": [
    "# $k$ Nearest Neighbors Classifier\n",
    "\n",
    "In this notebook will be some additional problems regarding the $k$-nearest neighbors classifier. This material corresponds to `Lectures/Supervised Learning/Classification/2. k Nearest Neighbors Classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07465a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b2247",
   "metadata": {},
   "source": [
    "##### 1. The \"perfect\" iris classifier\n",
    "\n",
    "##### a.\n",
    "\n",
    "Load the iris data set, then perform a train test split. Fit a $k$-nearest neighbors classifier on the training data with $k=1$. What is the accuracy of this model on the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ed16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to get the iris data\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "## import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Load the data\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris['data'],columns = ['sepal_length','sepal_width','petal_length','petal_width'])\n",
    "iris_df['iris_class'] = iris['target']\n",
    "\n",
    "## Making the split\n",
    "iris_train, iris_test = train_test_split(iris_df, \n",
    "                                            random_state=431,\n",
    "                                            shuffle=True,\n",
    "                                            test_size=.2,\n",
    "                                            stratify=iris_df['iris_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c0a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d78600",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424535bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e16305",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "The training accuracy of a $k$-nearest neighbors model with $k=1$ is always $1$, why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7517f4",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f39ef9",
   "metadata": {},
   "source": [
    "##### 2. Bias-Variance Tradeoff for KNN\n",
    "\n",
    "With $k$-nearest neighbors the complexity of the model is primarily controlled by the number of neighbors, $k$, considered when making a prediction.\n",
    "\n",
    "Which model do you expect to have the highest variance and which one do you expect to have the highest bias:\n",
    "- A model with $k=1$,\n",
    "- A model with $k=n$, where $n$ is the number of observations in the training set?\n",
    "\n",
    "In general which direction should you move $k$ to increase the bias, which direction to increase the variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922481c",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5232c",
   "metadata": {},
   "source": [
    "##### 3. Weighted Votes\n",
    "\n",
    "Sometimes it may be preferable to weight the votes, meaning that some of the $k$-nearest neighbors get more of a say in the predicted class. One common way to weight votes is by the inverse of the distance to the point you are trying to predict.\n",
    "\n",
    "Suppose you want to predict an output variable, $y$, with $\\mathcal{C}$ possible classes, using the $k$-nearest neighbors algorithm with a distance metric denoted with a $d$ (a standard choice is the euclidean distance $d(a,b) = \\sqrt{\\sum_{i=1}^m (a_i - b_i)^2}$ for two vectors $a,b \\in \\mathbb{R}^m$). Then the weighted version of $k$NN predicts that a new point $X^*$ would be the class $l$ for which:\n",
    "\n",
    "$$\n",
    "v_l = \\sum_{i \\in \\mathcal{N}(X^*)} \\frac{1}{d(X^*, X_i)} 1_{\\left\\lbrace y_i = l\\right\\rbrace},\n",
    "$$\n",
    "\n",
    "where $\\mathcal{N}(X^*)$ is the set of training points representing the $k$-nearest neighbors of $X^*$ and $1_{\\left\\lbrace y_i = l\\right\\rbrace}$ is $1$ when $y_i = l$ and $0$ when $y_i\\neq l$.\n",
    "\n",
    "For the iris data set perform cross-validation to investigate whether weighted $k$NN outperforms unweighted $k$NN in terms of the accuracy. Do this for $k=1,\\dots,10$.\n",
    "\n",
    "Look at the `KNeighborsClassifier` documentation, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html</a> to see how to implement weighted $k$NN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb851d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a547891",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a65f9",
   "metadata": {},
   "source": [
    "##### 4. Training and prediction times\n",
    "\n",
    "How is the training time for $k$-nearest neighbors impacted by the size of the training set, $n$, that is, as $n$ gets larger what happens to the training time?\n",
    "\n",
    "\n",
    "What happens to the prediction time, the time it takes for the algorithm to make a prediction, as $n$ gets larger?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb8401",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702df34",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58736da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
