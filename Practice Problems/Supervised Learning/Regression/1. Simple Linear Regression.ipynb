{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "\n",
    "In this notebook are some exercises to gain more experience with the material presented in the `Lectures/Supervised Learning/Regression/Simple Linear Regression` notebook.\n",
    "\n",
    "These problems provide some practice fitting models, and provide a stronger theoretical understanding of the technique as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the packages we'll use\n",
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import meshgrid\n",
    "import os\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Questions\n",
    "\n",
    "<b>Note: These questions cover some of the more theoretical concepts behind the algorithms/models we cover in the lecture videos/problem sessions. Sometimes these theoretical questions will require some knowledge of mathematics/statistics. If you approach a problem and you don't think that you have that knowledge yet, that's okay! You can always come back to that question at a later time :)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. An introduction to maximum likelihood estimation (MLE)\n",
    "\n",
    "In this question we will introduce the concept of maximum likelihood estimation to derive the formula for $\\hat{\\beta_1}$. Assume the standard SLR assumptions. Let $y$ denote the target variable, let $x$ denote the feature variable and suppose the true relationship between $y$ and $x$ is $y = \\beta_0 + \\beta_1 x + \\epsilon$. As usual assume there are $n$ observations.\n",
    "\n",
    "For now let's look at the first observation, $(x_1,y_1)$. The likelihood of observing $y_1$ given $x_1$ is\n",
    "$$\n",
    "f\\left(y_1|x_1;\\beta_0,\\beta_1\\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2}\\frac{\\left(y_1 - \\left(\\beta_0 + \\beta_1 x_1\\right)\\right)^2}{\\sigma^2}\\right)\n",
    "$$\n",
    "because we have assumed that $\\epsilon\\sim N(0,\\sigma)$. You can think of this as the probability of observing $y_1$ given $x_1$ and our model parameters. The goal of maximum likelihood estimation is to choose the parameters, in this case $\\beta_0$ and $\\beta_1$, that maximize the likelihood. \n",
    "\n",
    "Because we have assumed independence of our observations the likelihood of observing $y$ given $x$ is:\n",
    "$$\n",
    "f\\left(y|x;\\beta_0,\\beta_1\\right) = \\prod_{i=1}^n f\\left(y_i|x_i;\\beta_0,\\beta_1\\right) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{1}{2}\\frac{\\left(y_i - \\left(\\beta_0 + \\beta_1 x_i\\right)\\right)^2}{\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Take the partial derivatives of $f\\left(y|x;\\beta_0,\\beta_1\\right)$ with respect to $\\beta_0$ and $\\beta_1$, then set these equal to $0$ and solve to find the maximum likelihood estimator for simple linear regression.\n",
    "\n",
    "Hint: Try maximizing $\\log\\left(f\\left(y|x;\\beta_0,\\beta_1\\right)\\right)$ instead, because $\\log$ is a strictly increasing function this is the same as maximizing $f\\left(y|x;\\beta_0,\\beta_1\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write your answer here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Deriving the Standard Error for $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$\n",
    "\n",
    "When we estimate a parameter, say $\\theta$, we call the estimate of that parameter, $\\hat{\\theta}$, a statistic. Because we use a random sample of data observations to find $\\hat{\\theta}$, it has what is known as a sampling distribution. The standard error of an estimate is a measure of the variability of $\\hat{\\theta}$. You can find the standard error of the estimate, $\\hat{\\theta}$ by taking the square root of the variance of the estimate. \n",
    "\n",
    "Recall that the formula for $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ from SLR are:\n",
    "- $\\hat{\\beta_1} = \\frac{\\sum_{i=1}^n \\left( x_i - \\overline{x} \\right)\\left( y_i - \\overline{y} \\right)}{\\sum_{i=1}^n \\left( x_i - \\overline{x} \\right)^2}$ \n",
    "\n",
    "- $\\hat{\\beta_0} = \\overline{y} - \\hat{\\beta_1} \\overline{x}$\n",
    "\n",
    "First find the standard error of $\\hat{\\beta_1}$, then use that to find the standard error of $\\hat{\\beta_0}$. \n",
    "\n",
    "Hint: Recall that $\\overline{y} = \\sum_{i=1}^n y_i/n$ and $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Deriving the Standard Error for $E(y|x=x^*)$\n",
    "\n",
    "Use the solution to 2. to find the standard error of $E(y|x=x^*)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Application of previous answer: Confidence Interval for the Regression Line\n",
    "\n",
    "Let's take a look back at the model we're fitting:\n",
    "$$\n",
    "y = f(x) + \\epsilon = \\beta_0 + \\beta_1x + \\epsilon,\n",
    "$$\n",
    "where $\\epsilon$ is a vector of independent $\\epsilon_i \\sim N(0,\\sigma^2)$ for all $i$.\n",
    "\n",
    "Now take the expectation on both sides:\n",
    "$$\n",
    "E(y) = E(\\beta_0 + \\beta_1x + \\epsilon) = \\beta_0 + \\beta_1E(x) + E(\\epsilon) = \\beta_0 + \\beta_1E(x),\n",
    "$$\n",
    "this is where we got the formula for $\\hat{\\beta_0}$. \n",
    "\n",
    "Now let's say we know the value of $x$ for example $x^*$, in probability terms we're now looking at $y$ conditional on $X=x^*$ (denoted $y|x=x^*$), and then take the expectation:\n",
    "$$\n",
    "E(y|x=x^*) =  \\beta_0 + \\beta_1E(x^*) = \\beta_0 + \\beta_1 x^*,\n",
    "$$\n",
    "because we are looking at a specific value of $X$ so it is no longer random. \n",
    "\n",
    "So the regression line we've been plotting is actually a series of point estimates for the mean value of $y$ given a specific value of $x$. We've been denoting these point estimates as $\\hat{y}$. \n",
    "\n",
    "Just like we gave a confidence interval for $\\beta_1$ using our point estimate $\\hat{\\beta_1}$ we can give a confidence interval for $y|x$ using our point estimate $\\hat{y}$. The formula for the confidence interval for $E(y|x=x^*)$ is:\n",
    "$$\n",
    "\\hat{y} \\pm t_{n-2,(1-\\alpha/2)}\\sqrt{\\frac{\\sum_{i=1}^n\\left(y_i - \\hat{y_i}\\right)^2}{n-2}}\\sqrt{\\frac{1}{n} + \\frac{\\left(x^* - \\overline{x}\\right)^2}{(n-1)s_x^2}} \\approx \\hat{y} \\pm t_{n-2,(1-\\alpha/2)}\\sqrt{MSE}\\sqrt{\\frac{1}{n} + \\frac{\\left(x^* - \\overline{x}\\right)^2}{(n-1)s_x^2}},\n",
    "$$\n",
    "where $n$ is the number of observations and $t_{n-2,(1-\\alpha/2)}$ is such that $P(T\\geq t_{n-2,(1-\\alpha/2)}) = \\alpha/2$ for a random variable $T$ with a Studentized $t$ distribution with $n-2$ degrees of freedom. This formula still follows the confidence interval pattern, where here the product of the square roots is the standard error of $E(y|x=x^*)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Prediction Intervals for SLR\n",
    "\n",
    "Recall our discussion on confidence intervals for $E(y|x=x^*)$.\n",
    "\n",
    "In addition to a confidence interval for the conditional mean, you can also produce what are known as prediction intervals for $y|x=x^*$, which give us a sense of what reasonable lower and upper bounds are for $y|x=x^*$ for a given confidence level, $1-\\alpha$.\n",
    "\n",
    "Recall that the $(1-\\alpha)$ confidence interval formula for $E(y|x=x^*)$ was given by:\n",
    "$$\n",
    "\\hat{y} \\pm t_{n-2,(1-\\alpha/2)}\\sqrt{\\frac{\\sum_{i=1}^n\\left(y_i - \\hat{y_i}\\right)^2}{n-2}}\\sqrt{\\frac{1}{n} + \\frac{\\left(x^* - \\overline{x}\\right)^2}{(n-1)s_x^2}},\n",
    "$$\n",
    "\n",
    "The formula for the $(1-\\alpha)$ prediction interval is quite similar:\n",
    "$$\n",
    "\\hat{y} \\pm t_{n-2,(1-\\alpha/2)}\\sqrt{\\frac{\\sum_{i=1}^n\\left(y_i - \\hat{y_i}\\right)^2}{n-2}}\\sqrt{1 + \\frac{1}{n} + \\frac{\\left(x^* - \\overline{x}\\right)^2}{(n-1)s_x^2}}.\n",
    "$$\n",
    "The addition of $1$ in the second square root refelects the extra uncertainty involved in predicting the actual $y$ value for a value of $x$, and comes from the error term in the statistical models, $\\epsilon$. This does not show up with the confidence interval because remember $E(\\bullet)$ is linear and $E(\\epsilon)$ is assumed to be $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Carefully considering your data\n",
    "\n",
    "Read through this excellent article on how survivor and selection bias can impact the results of your linear regression. <i>Note: the model used in the article is a nonlinear regression, but the findings would be similar for simple linear regression</i>.\n",
    "    \n",
    "<a href=\"https://fivethirtyeight.com/features/faster-nfl-prospects-arent-always-better/\">https://fivethirtyeight.com/features/faster-nfl-prospects-arent-always-better/</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Mean absolute error\n",
    "\n",
    "When solving for the \"best\" estimates of $\\beta_0$ and $\\beta_1$ we minimized the mean squared error (MSE). This results in what is known as the Ordinary Least Squares estimates which have a number of desirable properties under the assumptions of linear regression. Alternatively we could have tried to minimize the mean absolute error (MAE) which is given more generally by:\n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{f}(X_i)|.\n",
    "$$\n",
    "\n",
    "One reason that this is not typically done is that the absolute value is not differentiable everywhere, making optimization annoying. However, as a metric the MAE is more \"robust\", meaning that a regression line fit by minimizing the MAE is less likely to drastically move if an outlier is added to or removed from the data set. \n",
    "\n",
    "To see this we return to a supervised learning framework where we use $m$ features stored in $X$ to predict $y$ by estimating this model:\n",
    "\n",
    "$$\n",
    "y = f(X) + \\epsilon.\n",
    "$$\n",
    "\n",
    "When estimating $f$ using the squared errors we want to minimize:\n",
    "\n",
    "$$\n",
    "E\\left(y - f(X) \\right)^2.\n",
    "$$\n",
    "\n",
    "It turns out that this is minimized exactly when:\n",
    "\n",
    "$$\n",
    "f(X) = E(y|X).\n",
    "$$\n",
    "\n",
    "Conversely, when estimating $f$ using the absolute errors we want to minimize:\n",
    "\n",
    "$$\n",
    "E \\left( | y - f(X) | \\right),\n",
    "$$\n",
    "\n",
    "which is minimized when:\n",
    "\n",
    "$$\n",
    "f(X) = \\text{median}\\left(y | X \\right),\n",
    "$$\n",
    "\n",
    "for an argument of why this is true see <a href=\"visualizing_the_median.pdf\">Visualizing the Median as the Minimum-Deviation Location</a> in this folder.\n",
    "\n",
    "As a statistic, the median is more robust to outliers than the mean, which explains why minimizing the MAE leads to more \"robust\" regression than minimizing the MSE. This more robust version of regression can be implemented in `sklearn` with `RANSACRegressor`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html#sklearn.linear_model.RANSACRegressor\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html#sklearn.linear_model.RANSACRegressor</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Questions\n",
    "\n",
    "##### 1. Origins of Regression to the Mean.\n",
    "\n",
    "Load in the data set `galton.csv` located in the `Data` folder.\n",
    "\n",
    "Create two subsets called `male` and `female`. \n",
    "\n",
    "Then reset the `father` variable in the `male` data set so that it is centered at the average `father` height. Do the same for the `mother` variable in the `female` data set.\n",
    "\n",
    "For the `male` data regress height on the father's height, for the female data regress height on the mother's height.\n",
    "\n",
    "Look at the estimates for $\\hat{\\beta_1}$ in both cases, what do these estimmates suggest about the height of the next generation?\n",
    "\n",
    "<i>Note that for this problem you do not need to worry about doing a train test split, this is because we will not be making a predictive model.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>father</th>\n",
       "      <th>mother</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>nkids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>M</td>\n",
       "      <td>73.2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>F</td>\n",
       "      <td>69.2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>F</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>F</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>75.5</td>\n",
       "      <td>66.5</td>\n",
       "      <td>M</td>\n",
       "      <td>73.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  family  father  mother sex  height  nkids\n",
       "0      1    78.5    67.0   M    73.2      4\n",
       "1      1    78.5    67.0   F    69.2      4\n",
       "2      1    78.5    67.0   F    69.0      4\n",
       "3      1    78.5    67.0   F    69.0      4\n",
       "4      2    75.5    66.5   M    73.5      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "galton = pd.read_csv('/Users/danieltuthill/Documents/code-2022/Data/galton.csv')\n",
    "galton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "male = galton.loc[galton.sex == 'M'].copy()\n",
    "male['father'] = male['father'] - male['father'].mean()\n",
    "female = galton.loc[galton.sex == 'F'].copy()\n",
    "female['mother'] = female['mother'] - female['mother'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code here\n",
    "# modelM = LinearRegression(copy_X = True)\n",
    "# modelM.fit(male.father.values.reshape(-1,1),\n",
    "#                   male.height.values)\n",
    "\n",
    "# modelF = LinearRegression(copy_X = True)\n",
    "# modelF.fit(female.mother.values.reshape(-1,1),\n",
    "#                   female.height.values)\n",
    "\n",
    "modelM = LinearRegression(copy_X = True)\n",
    "modelM.fit(male[['father']],\n",
    "                  male['height'])\n",
    "\n",
    "modelF = LinearRegression(copy_X = True)\n",
    "modelF.fit(female.mother.values.reshape(-1,1),\n",
    "                  female.height.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male beta_1_hat is 0.44774791760302524\n",
      "female beta_1_hat is 0.3265523065388858\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "print('male beta_1_hat is',modelM.coef_[0])\n",
    "print('female beta_1_hat is',modelF.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both estimates suggest that a child whose parent is tall is likely to be shorter than their parent, while a child whose parent is short is likely to be taller than their parent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. b) A Paradox?\n",
    "\n",
    "This phenomenon, where a child's height usually reverts to the population mean, would suggest that over time the population should converge to the average, right? \n",
    "\n",
    "What is incorrect with this line of reasoning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Estimating the standard deviation of $\\epsilon$.\n",
    "\n",
    "Recall that we assumed:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\epsilon,\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is a normally distributed random variable with variance $\\sigma^2$.\n",
    "\n",
    "\n",
    "It is often useful for us to have an estimate of $\\sigma$ because it allows us to give reasonable guesses for the possible values of $y$ for a given value of $x$.\n",
    "\n",
    "We estimate $\\sigma$ by finding the standard deviation of the <i>residuals</i>, which are the predicted values minus the actual values or:\n",
    "\n",
    "$$\n",
    "\\hat{y} - y.\n",
    "$$\n",
    "\n",
    "So if we have $n$ observations we have the following estimate for $\\sigma$:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma} = \\sqrt{\\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{n-2}} \\approx RMSE\n",
    "$$\n",
    "\n",
    "Load in this phony data, fit a simple linear regression model on it and estimate $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 8*np.random.random(100) - 4\n",
    "y = 2*x + 3*np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Code here\n",
    "model1 = LinearRegression(copy_X = True)\n",
    "model1.fit(x.reshape(-1,1),\n",
    "                  y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "residuals = model1.predict(x.reshape(-1,1)) - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.346780028861657\n"
     ]
    }
   ],
   "source": [
    "## Code here\n",
    "\n",
    "sigma = np.sqrt(np.sum(np.square(residuals))/(len(residuals)-2))\n",
    "print(sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Simulating data using your regression estimates\n",
    "\n",
    "We will end with one way you can use this estimate of $\\sigma$.\n",
    "\n",
    "Sometimes you may like to simulate \"new observations\" that follow the model you fit. This is possible using the fit   coefficient estimates and the estimate of $\\sigma$. To simulate new observations we just recall the simple linear regression model:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\epsilon,\n",
    "$$\n",
    "\n",
    "which can be estimated with:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1} x + \\hat{\\epsilon}, \n",
    "$$\n",
    "\n",
    "where $\\hat{\\epsilon} \\sim N(0,\\hat{\\sigma}).$\n",
    "\n",
    "Simulate $100$ new observations of $y$ using the estimates you obtained in 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "x_new = 8*np.random.random(100) - 4\n",
    "y_new = model1.intercept_ + model1.coef_[0]*x_new + sigma * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb3c9679190>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Code here\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.scatter(x_new,y_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Regressing backwards\n",
    "\n",
    "What happens if we accidentally regress $x$ on $y$?\n",
    "\n",
    "a. Load the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "y = x + np.random.randn(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. First, using either `numpy` or `sklearn` perform the regression correctly, meaning regress $y$ on $x$. Look at $\\hat{\\beta_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code here\n",
    "\n",
    "model2 = LinearRegression()\n",
    "model2.fit(x.reshape(-1,1),y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.002848312340573"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code here\n",
    "\n",
    "model2.coef_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Using either `numpy` or `sklearn` regress $x$ on $y$, then look at $\\hat{\\beta_1}$. Notice anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code here\n",
    "\n",
    "model3 = LinearRegression(copy_X = True)\n",
    "model3.fit(y.reshape(-1,1),x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681896933184198"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Now load in the new $y$ that has an $\\epsilon$ term with higher variance below, and refit the regression and look at $\\hat{\\beta_1}$. Notice anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2*np.random.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code here\n",
    "\n",
    "model3.fit(y.reshape(-1,1),x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9220931392055881"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code here\n",
    "\n",
    "model3.coef_[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Finish the `for` loop code that records the $\\hat{\\beta_1}$ for errors with increasing variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1_hats = []\n",
    "\n",
    "for c in np.linspace(.1,100,10000):\n",
    "    y = x + c*np.random.randn(1000)\n",
    "    \n",
    "    ## make a regression object here\n",
    "    slr = LinearRegression(copy_X = True)    \n",
    "    \n",
    "    # fit the slr here\n",
    "    slr.fit(y.reshape(-1,1),x)\n",
    "    \n",
    "    \n",
    "    # append the estimate to beta_1_hats here\n",
    "    beta_1_hats.append(slr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Plot the $\\hat{\\beta_1}$s as a function of `c`. What happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (10000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## code here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbeta_1_hats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/erdos/lib/python3.8/site-packages/matplotlib/pyplot.py:2769\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2767\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2770\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2771\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/erdos/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/anaconda3/envs/erdos/lib/python3.8/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/erdos/lib/python3.8/site-packages/matplotlib/axes/_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (10000,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## code here\n",
    "plt.plot(c,beta_1_hats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\beta_1} = \\frac{\\sum_{i=1}^n \\left( x_i - \\overline{x}\\right)\\left( y_i - \\overline{y} \\right)}{\\sum_{i=1}^n \\left(x_i - \\overline{x} \\right)^2} = \\frac{\\text{cov}(x,y)}{\\text{var}(x)},\n",
    "$$\n",
    "\n",
    "f. Recall the formula for $\\hat{\\beta_1}$ for a regression of $y$ on $x$ given above. If we assume that $y = \\beta_0 + \\beta_1 x + \\epsilon$ and then regress $x$ on $y$, what happens to the value of $\\hat{\\beta_1}$ as the variance of $\\epsilon$ goes to $\\infty$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
