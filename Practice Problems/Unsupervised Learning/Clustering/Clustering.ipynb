{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "This notebook will contain some homework questions about $k$ mmeans clustering  and hiearchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a dark background\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. $k$ means random initialization\n",
    "\n",
    "Recall that $k$ means clustering starts by choosing an initial guess for $k$ centroids. This is typically done with a random guess. Because $k$ means clustering is a greedy algorithm, there is no guarantee that the resulting clusters are identical across separate runs (unless you set a random seed). Moreover, this means that some random initial centroids may result in \"better\" clusterings than others, where we take better to mean lower inertia.\n",
    "\n",
    "A common approach to deal with this is to run the algorithm multiple times with a different random initial set of centroids each time, and then choose the run that provided the lowest inertia.\n",
    "\n",
    "In `sklearn` the default is to run the $k$ means algorithm $10$ times, however, this can be changed with the `n_init` argument.\n",
    "\n",
    "Generate the following data and then manually run the clustering $10$ times. Do this by fitting $10$ unique `KMeans` objects with `n_init = 1`. Which clustering has the lowest inertia, the highest average silhouette score? Set $k=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((300,2))\n",
    "\n",
    "X[:100,:] = np.random.randn(100,2)\n",
    "X[100:200,:] = np.random.randn(100,2) + np.array([2, 2])\n",
    "X[200:,:] = np.random.randn(100,2) + np.array([-2, 2])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Return to MNIST\n",
    "\n",
    "In this problem we will play around with the MNIST data set (alternatively you could play around the MNIST of fashion if you prefer).\n",
    "\n",
    "First load the keras version of the MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the MNIST data here (or MNIST fashion if you'd like)\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data here\n",
    "\n",
    "\n",
    "## reshape the training data so there are 60000 rows of 28*28 columns\n",
    "## Also scale the data by dividing by 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training data through $k$ means clustering with $50$ clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of the centers of each resulting cluster as the \"average\" image for that cluster. It can be interesting to look at this image to see what kinds of observations are represented in this cluster.\n",
    "\n",
    "Choose a few of the clusters and use `imshow` to plot their corresponding `cluster_centers_`. At the same time calculate the percentage of each image type (digit for MNIST, fashion item for the fasion MNIST) in that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you found an interesting cluster you could also plot the observations in that cluster to see in finer detail what's going on in that cluster. Choose a single cluster, then choose a random sample of observations within that cluster to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Make any notes you might like here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This repository was written for the 2021 Erdős Institute Fall Data Science Semester by Matthew Osborne, Ph. D., 2021.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute. (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
