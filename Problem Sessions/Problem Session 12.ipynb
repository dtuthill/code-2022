{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ad9132",
   "metadata": {},
   "source": [
    "# Problem Session 12\n",
    "## MNIST of Fashion II\n",
    "\n",
    "In this notebook you will work on problems that relate to our neural network content. In particular, this material will touch on the following lecture notebooks:\n",
    "- `Lectures/Neural Networks/2. The MNIST Data Set`,\n",
    "- `Lectures/Neural Networks/3. Multilayer Neural Networks`,\n",
    "- `Lectures/Neural Networks/4. keras`,\n",
    "- `Lectures/Neural Networks/5. Introduction to Convolutional Neural Networks` and\n",
    "- `Lectures/Neural Networks/7. Loading Pre-Trained Models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9befd",
   "metadata": {},
   "source": [
    "##### 1. Load the data\n",
    "\n",
    "In this notebook you will continue to work to build neural networks to classify images of common fashion items. First run the code below in order to load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## docs: https://keras.io/api/datasets/fashion_mnist/\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This can take a little bit to run,\n",
    "## especially if it is your first time running this code\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "label_dict = {0:\"T-shirt/top\",\n",
    "                 1:\"Trouser\",\n",
    "                 2:\"Pullover\",\n",
    "                 3:\"Dress\",\n",
    "                 4:\"Coat\",\n",
    "                 5:\"Sandal\",\n",
    "                 6:\"Shirt\",\n",
    "                 7:\"Sneaker\",\n",
    "                 8:\"Bag\",\n",
    "                 9:\"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa5f068",
   "metadata": {},
   "source": [
    "##### 2. Validation set and scaling\n",
    "\n",
    "Create a validation set with $20\\%$ of the training set. Also scale the data by dividing by the maximum pixel value, $255$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca542f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale data here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b2f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tt, X_val, y_tt, y_val = train_test_split(X_train, y_train,\n",
    "                                               shuffle=True,\n",
    "                                               random_state=213,\n",
    "                                               test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db0bd60",
   "metadata": {},
   "source": [
    "##### 3. Loading a feed forward model\n",
    "\n",
    "In `Problem Session 11` you worked to build a number of feed forward models for this classification problem. If your group was able to make it to the end of that notebook you would have saved the neural network model that performed best.\n",
    "\n",
    "Load the model here for comparison purposes at the end of this notebook.\n",
    "\n",
    "<i>If you were not able to save a model while working on `Problem Session 11`, you can load `nb11_matts_final_model` here. This model was trained on the PCA transformed version of the data.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbfddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import load_model here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828bbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load_model here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa63467",
   "metadata": {},
   "source": [
    "##### 4. A first convolutional neural network\n",
    "\n",
    "As a first convolution neural network, try building a CNN with a single convolutional layer of depth $64$ using a $3\\times 3$ filter followed by a pooling layer using a $2\\times 2$ filter with size $2$ strides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import what you need from keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make convolutional neural net reshaped versions\n",
    "## of the training and validation data\n",
    "X_tt_conv = \n",
    "X_val_conv = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an empty sequential model\n",
    "model1 = \n",
    "\n",
    "## Add the convolutional layer here\n",
    "model1.add( layers.Conv2D() )\n",
    "\n",
    "## Add the pooling layer here\n",
    "model1.add( layers.MaxPooling2D() )\n",
    "\n",
    "## Add the flatten layer\n",
    "model1.add(layers.Flatten())\n",
    "\n",
    "## Add the feed forward layer, use 64 nodes\n",
    "model1.add()\n",
    "\n",
    "## Add the output layer\n",
    "model1.add()\n",
    "\n",
    "## Same compile step from notebook 11\n",
    "model1.compile(optimizer = 'rmsprop',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6279b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit the model for 25 epochs, this can take a bit\n",
    "n_epochs=23\n",
    "history1 = model1.fit(X_tt_conv, \n",
    "                      to_categorical(y_tt), \n",
    "                      epochs=n_epochs, \n",
    "                      batch_size=512,\n",
    "                      validation_data=(X_val_conv,to_categorical(y_val)))\n",
    "\n",
    "history_dict1 = history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3669a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the training set accuracy and the validation set accuracy\n",
    "## against the number of epochs trained\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            label=\"Training Data\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            marker='v',\n",
    "            label=\"Validation Data\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e2543",
   "metadata": {},
   "source": [
    "##### 5. Adding in padding\n",
    "\n",
    "Add in the `padding='same'` argument to the convolutional layer from the network above. Fit this network and compare the validation accuracies for `model2` and `model1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a324ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an empty sequential model\n",
    "model2 = models.Sequential()\n",
    "\n",
    "## Add the convolutional layer here, don't forget the padding\n",
    "\n",
    "\n",
    "## Add the pooling layer here\n",
    "\n",
    "\n",
    "## Add the flatten layer\n",
    "\n",
    "\n",
    "## Add the feed forward layer, use 64 nodes\n",
    "\n",
    "\n",
    "## Add the output layer\n",
    "\n",
    "\n",
    "## Same compile step from notebook 11\n",
    "model2.compile(optimizer = 'rmsprop',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf154311",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_tt_conv, \n",
    "                      to_categorical(y_tt), \n",
    "                      epochs=n_epochs, \n",
    "                      batch_size=512,\n",
    "                      validation_data=(X_val_conv,to_categorical(y_val)))\n",
    "\n",
    "history_dict2 = history2.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfdafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the validation set accuracy for model1 and model2\n",
    "## against the number of epochs trained\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            label=\"No Padding\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            marker='v',\n",
    "            label=\"Padding\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c9ef0",
   "metadata": {},
   "source": [
    "How does the performance compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35065a1",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b2ec5",
   "metadata": {},
   "source": [
    "##### 6. Adding a dropout layer\n",
    "\n",
    "Sometimes while building convolutional or recurrent neural networks you will add what is known as a <i>dropout</i> layer before the final feed forward layer of the network.\n",
    "\n",
    "A dropout layer will randomly turn off input nodes with a probability that you select when setting up the network. For example a dropout layer with probability $0.25$ will turn each of the input nodes to $0$ with probability $0.25$. \n",
    "\n",
    "This may seem counterintuitive because we will be getting rid of some of the work the previous layers of our network have done. However, neural networks have a ton of parameters, meaning that they tend to overfit on the training data. By randomly turning some nodes to $0$ we lessen the networks ability to overfit, which may in turn improve performance on observations not included in the training set.\n",
    "\n",
    "For `model3` use your results from above to choose either `model1` or `model2` and then add a dropout layer between  the `.Flatten()` layer and the `Dense(64)` layer. Dropout layers can be inserted in `keras` with `layers.Dropout(dropout_probability)`, <a href=\"https://keras.io/api/layers/regularization_layers/dropout/\">https://keras.io/api/layers/regularization_layers/dropout/</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d8eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an empty sequential model\n",
    "model3 = models.Sequential()\n",
    "\n",
    "## Add the convolutional layer here\n",
    "\n",
    "\n",
    "\n",
    "## Add the pooling layer here\n",
    "\n",
    "\n",
    "\n",
    "## Add the flatten layer\n",
    "\n",
    "\n",
    "\n",
    "## Add the dropout layer, set the dropout probability to .5\n",
    "\n",
    "\n",
    "## Add the feed forward layer, use 64 nodes\n",
    "\n",
    "\n",
    "\n",
    "## Add the output layer\n",
    "\n",
    "\n",
    "## Same compile step from notebook 11\n",
    "model3.compile(optimizer = 'rmsprop',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be378b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit(X_tt_conv, \n",
    "                      to_categorical(y_tt), \n",
    "                      epochs=n_epochs, \n",
    "                      batch_size=512,\n",
    "                      validation_data=(X_val_conv,to_categorical(y_val)))\n",
    "\n",
    "history_dict3 = history3.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the validation set accuracy for your chosen model and model3\n",
    "## against the number of epochs trained\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            label=\"No Dropout\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            marker='v',\n",
    "            label=\"With Dropout\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0663a33a",
   "metadata": {},
   "source": [
    "How does the model with dropout compare to the equivalent model without dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf69117",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d391b6",
   "metadata": {},
   "source": [
    "##### 6. Choosing a final convolutional neural network model\n",
    "\n",
    "Select one convolutional neural network model from the three models we have considered in this notebook.\n",
    "\n",
    "Remake the model and train it to the appropriate number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an empty sequential model\n",
    "cnn_final_model = models.Sequential()\n",
    "\n",
    "## Add the convolutional layer here\n",
    "\n",
    "\n",
    "## Add the pooling layer here\n",
    "\n",
    "\n",
    "## Add the flatten layer\n",
    "\n",
    "\n",
    "## Add the dropout layer, set the dropout probability to .5\n",
    "\n",
    "\n",
    "## Add the feed forward layer, use 64 nodes\n",
    "\n",
    "\n",
    "## Add the output layer\n",
    "\n",
    "\n",
    "## Same compile step from notebook 11\n",
    "cnn_final_model.compile(optimizer = 'rmsprop',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn_final = cnn_final_model.fit(X_tt_conv, \n",
    "                      to_categorical(y_tt), \n",
    "                      epochs=20, \n",
    "                      batch_size=512,\n",
    "                      validation_data=(X_val_conv,to_categorical(y_val)))\n",
    "\n",
    "history_dict_cnn_final = history_cnn_final.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9afc9",
   "metadata": {},
   "source": [
    "##### 7. Compare to feed forward\n",
    "\n",
    "Compare the validation set accuracy of this network to the accuracy from the pre-trained model you loaded.\n",
    "\n",
    "<i>If you are using `nb11_matts_final_model` you will need to run the data through PCA trained on the training set with `n_components = .99`</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c37968",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write the Feed forward validation accuracy here\n",
    "accuracy_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write the CNN validation accuracy here\n",
    "accuracy_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dbfeef",
   "metadata": {},
   "source": [
    "##### 8. Performance on the test set\n",
    "\n",
    "While you are free to fiddle around and try additional neural networks, this problem assumes that you have landed on a final network.\n",
    "\n",
    "Gauge the performance of your final network on the test set.\n",
    "\n",
    "Compare it to its performance on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note you first have to retrain the model on the entire training set\n",
    "del cnn_final_model\n",
    "\n",
    "\n",
    "## Make an empty sequential model\n",
    "cnn_final_model = models.Sequential()\n",
    "\n",
    "## copy and paste your final model here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc196a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_cnn_final = cnn_final_model.fit(X_train.reshape(-1, 28, 28, 1), \n",
    "                      to_categorical(y_train), \n",
    "                      epochs=20, \n",
    "                      batch_size=512)\n",
    "\n",
    "history_dict_cnn_final = history_cnn_final.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86724e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set accuracy\")\n",
    "print(\"++++++++++++++++++++++++++++\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddf147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set accuracy\")\n",
    "print(\"++++++++++++++++++++++++++++\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f644682f",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb54a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
