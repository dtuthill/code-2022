{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42365a08",
   "metadata": {},
   "source": [
    "# Problem Session 11\n",
    "## MNIST of Fashion I\n",
    "\n",
    "In this notebook you will work on problems that relate to our neural network content. In particular, this material will touch on the following lecture notebooks:\n",
    "- `Lectures/Neural Networks/1. Perceptrons`,\n",
    "- `Lectures/Neural Networks/2. The MNIST Data Set`,\n",
    "- `Lectures/Neural Networks/3. Multilayer Neural Networks` and\n",
    "- `Lectures/Neural Networks/4. keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16036743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5cbb2",
   "metadata": {},
   "source": [
    "##### 1. Load the data\n",
    "\n",
    "In this notebook you will work to build neural networks to classify images of common fashion items. First run the code below in order to load the data set. Then we will discuss the data more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95907262",
   "metadata": {},
   "outputs": [],
   "source": [
    "## docs: https://keras.io/api/datasets/fashion_mnist/\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c97ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This can take a little bit to run,\n",
    "## especially if it is your first time running this code\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "label_dict = {0:\"T-shirt/top\",\n",
    "                 1:\"Trouser\",\n",
    "                 2:\"Pullover\",\n",
    "                 3:\"Dress\",\n",
    "                 4:\"Coat\",\n",
    "                 5:\"Sandal\",\n",
    "                 6:\"Shirt\",\n",
    "                 7:\"Sneaker\",\n",
    "                 8:\"Bag\",\n",
    "                 9:\"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de22fcc",
   "metadata": {},
   "source": [
    "##### 2. Learn about the data set\n",
    "\n",
    "This data set is an equivalent of the MNIST data set, but with scans of common fashion items instead of hand-drawn instances of the digits $0-9$. The ten different items featured in this data set can be seen in the code chunk above in the `label_dict` variable.\n",
    "\n",
    "First answer these questions, then run the prewritten code to see a few example images. \n",
    "\n",
    "- How many observations are in the training set? \n",
    "- How many in the test set? \n",
    "- What are the dimensions of the pixel grid for each image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4696e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f557dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b8aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b35721",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## This plots the first 8 training images\n",
    "fig,ax = plt.subplots(4,2, figsize=(20,40))\n",
    "\n",
    "for i in range(8):\n",
    "    ax[i//2, i%2].imshow(X_train[i], cmap='gray')\n",
    "    ax[i//2, i%2].text(.5,.5,label_dict[y_train[i]], c=\"white\", fontsize=16)\n",
    "    ax[i//2, i%2].axis(\"off\")\n",
    "    \n",
    "plt.subplots_adjust(hspace=.1,wspace=.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3279d6bf",
   "metadata": {},
   "source": [
    "##### 3. Validation set\n",
    "\n",
    "Make a validation set from the training set. Use $20\\%$ of the training set. We will use this to compare neural net performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b39de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c67a8",
   "metadata": {},
   "source": [
    "##### 4. Prepare the data\n",
    "\n",
    "The maximum value of any pixel in these images is `255`, the minimum value of any pixel is `0`.\n",
    "\n",
    "Using this information scale the data so that the maximum value goes to `1` and the minimum value goes to `0`.\n",
    "\n",
    "Then reshape the array so that it is a two dimensional array, i.e. each column represents a single pixel while each row represents a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale here\n",
    "\n",
    "\n",
    "\n",
    "## Reshape here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8603cf4",
   "metadata": {},
   "source": [
    "##### 5. Your first neural network\n",
    "\n",
    "We will start by building a feed forward network with a single hidden layer using `keras`. \n",
    "\n",
    "Fill in the missing code below to build and fit this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be749a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the following\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "### If you have an earlier version of keras ###\n",
    "# from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf44023",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make an empty model here with models.Sequential\n",
    "## only run this once\n",
    "model1 =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc952761",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ONLY Run this once, when your code is entered ###\n",
    "## Add the first Dense layer, \n",
    "## give it 100 nodes\n",
    "## the 'relu' acitavtion function and\n",
    "## don't forget to set the input_shape\n",
    "model1.add(  )\n",
    "\n",
    "\n",
    "## Add the output layer\n",
    "## This is a Dense layer\n",
    "## it should have 10 nodes, because our data has 10 classes\n",
    "## and its activation function should be the 'softmax'\n",
    "model1.add(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use model.summary to look at the architecture of your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ONLY RUN ONCE ####\n",
    "## Compile the model here\n",
    "## Use the `rmsprop` optimizer,\n",
    "## the 'categorical_crossentropy' loss function\n",
    "## and return 'accuracy' as a metric\n",
    "model1.compile(optimizer = \n",
    "                 loss = \n",
    "                 metrics = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d77889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## fit the model and store the history in a variable\n",
    "## train for 100 epochs,\n",
    "## use a batch size of 512\n",
    "## remember to apply to_categorical to y\n",
    "## and include the validation_data\n",
    "n_epochs = \n",
    "\n",
    "history1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c1ecd",
   "metadata": {},
   "source": [
    "##### 6. Examine the accuracy\n",
    "\n",
    "Plot the accuracy of the model on both the validation and training sets. Does it look like we chose enough epochs, or should we have used more than $100$? Does it look the model has started to overfit on the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## store the history dictionary in history_dict1\n",
    "history_dict1 = history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "plt.scatter(range(1, n_epochs+1), \n",
    "            , \n",
    "            label=\"Training Data\")\n",
    "plt.scatter(range(1, n_epochs+1), \n",
    "            ,\n",
    "            marker='v',\n",
    "            label=\"Validation Data\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30220b",
   "metadata": {},
   "source": [
    "##### 7. A network with two layers\n",
    "\n",
    "Now make a network with two hidden layers for this problem. You choose the architecture (the size of each of the two hidden layers). Compare the accuracies on the validation set for the first model and this model. Which one seems to perform better? Choose one of these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327d0fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## make a sequential model\n",
    "model2 = \n",
    "\n",
    "\n",
    "## Add the layers\n",
    "\n",
    "## layer 1\n",
    "\n",
    "\n",
    "## layer 2\n",
    "\n",
    "\n",
    "\n",
    "## out layer\n",
    "\n",
    "\n",
    "\n",
    "## compile the network\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## fit the network\n",
    "history2 = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history_dict2 = history2.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1670aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            label=\"Network 1\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            marker='v', \n",
    "            label=\"Network 2\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f370c4c",
   "metadata": {},
   "source": [
    "##### 8. PCA preprocessing\n",
    "\n",
    "It is possible that preprocessing the data by running it through PCA first could help.\n",
    "\n",
    "Try a neural network fit to PCA transformed data. Note that because we scaled the pixels earlier, we do not need to run the data through `StandardScaler` prior to PCA. Make sure you remember to transform the validation set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ffc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd258b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a pca object with n_componenets = .99\n",
    "\n",
    "\n",
    "\n",
    "## fit the pca on X_tt\n",
    "\n",
    "\n",
    "\n",
    "## transform X_tt\n",
    "\n",
    "\n",
    "\n",
    "## transform X_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d25d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Build the network on the pca data here\n",
    "## make a sequential model\n",
    "model3 =  \n",
    "\n",
    "\n",
    "## Add the layers\n",
    "\n",
    "## Hidden layers here\n",
    "\n",
    "\n",
    "## output layer here\n",
    "\n",
    "\n",
    "\n",
    "## compile the network\n",
    "\n",
    "\n",
    "\n",
    "## fit the network\n",
    "history3 = \n",
    "\n",
    "history_dict3 = history3.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare the accuracy on the pca and non-pca networks\n",
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict2['val_accuracy'], \n",
    "            label=\"Non-PCA network\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict3['val_accuracy'], \n",
    "            marker='v', \n",
    "            label=\"PCA network\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b37fe0",
   "metadata": {},
   "source": [
    "Which would you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1b667",
   "metadata": {},
   "source": [
    "##### 9. Play around\n",
    "\n",
    "Feel free to play around and build more networks here. Can you build a network that improves upon the best one you have built so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ec6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee9759",
   "metadata": {},
   "source": [
    "##### 10. Saving a trained model.\n",
    "\n",
    "When you have a model that you are happy with, make a fresh version of the model and train it using the optimal number of epochs. Then run the code below to save the trained model on your computer. We will see how to load this model in a later lecture notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and train your final model here\n",
    "final_model =  models.Sequential()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d289a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code will save the final model\n",
    "final_model.save(\"PUT_IN_YOUR_MODEL_NAME_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31fce12",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be59515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
