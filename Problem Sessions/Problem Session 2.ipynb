{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42f5fd8",
   "metadata": {},
   "source": [
    "# Problem Session 2\n",
    "## Intro to Supervised Learning & Simple Linear Regression\n",
    "\n",
    "The problems in this notebook will cover the content covered in our introductory `Supervised Learning` and `Regression` lectures including:\n",
    "- `A Supervised Learning Framework`,\n",
    "- `Data Splits for Predictive Modeling` and\n",
    "- `Simple Linear Regression`.\n",
    "\n",
    "They also serve as a good lead-in to `A First Predictive Modeling Project`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023a218",
   "metadata": {},
   "source": [
    "##### 1. Introducing `carseats.csv`\n",
    "\n",
    "In this notebook you will work with a data set provided by <a href=\"https://www.statlearning.com/\">An Introduction to Statistical Learning</a>. These data provide the sales (in thousands) of child car seats at fictional retailers along with various features that may or may not be related to those sales figures. You can find descriptions of each variable in this data set here, <a href=\"https://rdrr.io/cran/ISLR/man/Carseats.html\">https://rdrr.io/cran/ISLR/man/Carseats.html</a>.\n",
    "\n",
    "##### a. Load the data\n",
    "\n",
    "The file `carseats.csv` is stored in the `Data` folder. Load the data in using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import anything you need here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ec2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346892b7",
   "metadata": {},
   "source": [
    "##### b. What is it?\n",
    "\n",
    "What kind of supervised learning problem could be solved with this data set, regression or classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046c335",
   "metadata": {},
   "source": [
    "##### Write your answer here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0a7b8",
   "metadata": {},
   "source": [
    "##### c. Use cases\n",
    "\n",
    "Describe specific example(s) of how these data could be used for:\n",
    "1. Making predictions and\n",
    "2. Making inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284925b",
   "metadata": {},
   "source": [
    "##### Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25457307",
   "metadata": {},
   "source": [
    "##### d. Data set size\n",
    "\n",
    "How many observations are in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa9008",
   "metadata": {},
   "source": [
    "#### Predictive Model\n",
    "\n",
    "You have been tasked by the Carseats Corporation to build a predictive model using these data. Specifically, corporate wants a model that predicts carseat `Sales`.\n",
    "\n",
    "In this notebook we will restrict ourselves to a single feature model, but more on that soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739961e1",
   "metadata": {},
   "source": [
    "##### 2. Train test split\n",
    "\n",
    "The first step in predictive modeling is performing a train test split. Perform a train test split on these data, setting aside $20\\%$ of the data as a test set. Choose a `random_state` so your results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b16090",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71320a",
   "metadata": {},
   "source": [
    "##### 3. Exploratory data analysis (EDA)\n",
    "\n",
    "After a train test split it is typical that you will explore your data set a bit. This step is sometimes called <i>exploratory data analysis</i> or <i>EDA</i> for short. Here you will work through a guided EDA.\n",
    "\n",
    "##### a. Scatter Plots\n",
    "\n",
    "For this first modeling notebook we will stick to models that use a single quantitative/continuous feature to predict `Sales`, this means we are most interested in any predictive relationship that may exist between `Sales` and the following columns:\n",
    "- `CompPrice`,\n",
    "- `Income`,\n",
    "- `Advertising`,\n",
    "- `Population`,\n",
    "- `Price`,\n",
    "- `Age` and\n",
    "- `Education`.\n",
    "\n",
    "Make scatter plots with `Sales` on the vertical axis and these other columns on the horizontal axis.\n",
    "\n",
    "These could be individual plots or a <i>scatter matrix</i>, which is a matrix of scatter plots. <i>A scatter matrix can be quickly created with `seaborn`'s `pairplot` function, <a href=\"https://seaborn.pydata.org/generated/seaborn.pairplot.html\">https://seaborn.pydata.org/generated/seaborn.pairplot.html</a> or `pandas`'s `scatter_matrix` function, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html\">https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html</a>.</i>\n",
    "\n",
    "When making these plots, you should look for which feature appears to have the biggest impact on `Sales`.\n",
    "\n",
    "<b>Note:</b> you should only use the training set for EDA when doing predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fdbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import anything you need here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb45dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851fcc1",
   "metadata": {},
   "source": [
    "##### b. Pearson correlation\n",
    "\n",
    "Another part of EDA is calculating descriptive statistics.\n",
    "\n",
    "One statistic of interest to us in this situation is the <i>Pearson correlation coefficient</i>. For two variables $x$ and $y$ with $n$ observations each the Pearson correlation is given by:\n",
    "\n",
    "$$\n",
    "r = \\frac{\\sum_{i=1}^n \\left( x_i - \\overline{x} \\right) \\left( y_i - \\overline{y}  \\right)}{\\sqrt{\\sum_{i=1}^n \\left(x_i - \\overline{x}\\right)^2 \\sum_{i=1}^n \\left(y_i - \\overline{y} \\right)^2}} = \\frac{\\text{cov}\\left(x, y\\right)}{\\sigma_x \\sigma_y},\n",
    "$$\n",
    "\n",
    "where $x_i$ is the $i^\\text{th}$ observation, $\\overline{x} = \\sum_{i=1}^n x_i/n$, $\\text{cov}\\left( x, y \\right)$ is the covariance between $x$ and $y$, and $\\sigma_x$ denotes the standard deviation of $x$.\n",
    "\n",
    "$r \\in [-1,1]$ gives a sense of the strength of the linear relationship between $x$ and $y$. The closer to $1$ $|r|$ is, the stronger the linear relationship between $x$ and $y$, the sign of $r$ determines the direction of the relationship, with $r < 0$ meaning a line with a negative slope and $r > 0$ a line with a positive slope.\n",
    "\n",
    "Calculate the correlation between `Sales` and the previously mentioned columns.\n",
    "\n",
    "<i>Hint: If you are unsure how to do this quickly, perform a web search like \"pandas correlation\" or \"numpy correlation\"</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d5de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a67c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb70805",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccab120",
   "metadata": {},
   "source": [
    "##### c. Choosing a feature\n",
    "\n",
    "Using the EDA you just completed choose a single feature to use to predict `Sales`.\n",
    "\n",
    "<i>Your answer should be one of:</i>\n",
    "- `CompPrice`,\n",
    "- `Income`,\n",
    "- `Advertising`,\n",
    "- `Population`,\n",
    "- `Price`,\n",
    "- `Age` and\n",
    "- `Education`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02177c58",
   "metadata": {},
   "source": [
    "###### Write here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0abcd8",
   "metadata": {},
   "source": [
    "##### 4. Modeling\n",
    "\n",
    "Now we will work to build some predictive models. By the end of this question you will have built three predictive models and compared them using cross-validation.\n",
    "\n",
    "##### a. A baseline\n",
    "\n",
    "When doing predictive modeling it is good practice to have <i>baseline model</i> which is a simple \"model\" solely for comparison purposes. These are not typically, complex or good models, but they are important reference points to give us a sense of how well our models are actually performing.\n",
    "\n",
    "A standard regression model baseline is to just predict the average value of $y$ for any value of $X$. In this setting that model looks like this:\n",
    "\n",
    "$$\n",
    "\\text{Baseline Model: } \\ \\ \\ \\ \\text{Sales} = E(\\text{Sales}) + \\epsilon,\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is some random noise.\n",
    "\n",
    "Write some code to estimate $E(\\text{Sales})$ using our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa48c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15c31a",
   "metadata": {},
   "source": [
    "##### b. Simple linear regression\n",
    "\n",
    "Follow the steps laid out below to fit a simple linear regression model regressing `Sales` on the feature you chose at the end of your EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fe438",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a model object here\n",
    "\n",
    "\n",
    "\n",
    "## Fit the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c2dbec",
   "metadata": {},
   "source": [
    "##### c. $k$ nearest neighbors regression\n",
    "\n",
    "An alternative regression model that we will learn about later is called $k$ nearest neighbors regression. This model works by taking the average value of $y$ for $X$'s $k$ nearest neighbors in the training set. There will be a lecture notebook explaining this model more clearly, for now just use it as practice for making and fitting a model object in `sklearn`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html</a>.\n",
    "\n",
    "Follow the prompts in the code chunks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a KNeighborsRegressor object with k = 5\n",
    "## This can be done by calling KNeighborsRegressor(5)\n",
    "knr = \n",
    "\n",
    "## Fit the model with your chose feature\n",
    "## This is done in the same way as you fit simple linear regression\n",
    "knr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315c961",
   "metadata": {},
   "source": [
    "##### d. Plot the three models\n",
    "\n",
    "Before properly evaluating the models let's visualize them on our training set.\n",
    "\n",
    "Make a figure that plots the following things:\n",
    "- The training data with `Sales` on the vertical axis and your feature on the horizontal axis,\n",
    "- The baseline model plotted as a solid red line,\n",
    "- The simple linear regression model plotted as a black dotted line and\n",
    "- The $k$ nearest neighbors regression model plotted as a magenta dot-dash line.\n",
    "\n",
    "There is some helpful code already written below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec2ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making the figure\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "\n",
    "## Place the scatter plot here\n",
    "plt.scatter()\n",
    "\n",
    "## place the string of your chose feature here\n",
    "feature = \n",
    "\n",
    "## Use this variable to make model lines\n",
    "x = np.linspace(car_train[feature].min() - 2, car_train[feature].max() + 2, 100)\n",
    "\n",
    "## Plotting the models ##\n",
    "## Baseline\n",
    "plt.plot(x, car_train.Sales.mean()*np.ones(100), 'r-', label=\"Baseline\")\n",
    "\n",
    "## SLR\n",
    "plt.plot(x, slr.predict(x.reshape(-1,1)), 'k--', linewidth = 1.5, label=\"SLR\")\n",
    "\n",
    "## KNR\n",
    "plt.plot(x, knr.predict(x.reshape(-1,1)), 'm-.', linewidth = 1.5, label=\"KNR\")\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.xlabel(feature, fontsize=18)\n",
    "plt.ylabel(\"Sales\", fontsize=18)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc66b0a",
   "metadata": {},
   "source": [
    "##### e. Cross-Validation \n",
    "\n",
    "In this problem you will try to implement $5$-fold cross-validation (CV) to compare these three models to see which one has the lowest average cross-validation mean squared error (MSE).\n",
    "\n",
    "Because this may be your first time implementing CV, some of the code will be filled in for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ba4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import KFold here\n",
    "\n",
    "\n",
    "## import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aba559",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a KFold object\n",
    "## remember to set a random_state and set shuffle = True\n",
    "kfold = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## This array will hold the mse for each model and split\n",
    "mses = np.zeros((3, 5))\n",
    "\n",
    "## sets a split counter\n",
    "i = 0\n",
    "\n",
    "## loop through the kfold here\n",
    "\n",
    "    ## cv training set\n",
    "    car_tt = \n",
    "    \n",
    "    ## cv holdout set\n",
    "    car_ho = \n",
    "    \n",
    "    ## \"Fit\" and get ho mse for the baseline model\n",
    "    baseline_pred = \n",
    "    \n",
    "    mses[0, i] = \n",
    "    \n",
    "    ## Fit and get ho mse for slr\n",
    "    slr = \n",
    "    \n",
    "    slr.fit()\n",
    "    \n",
    "    mses[1, i] = \n",
    "    \n",
    "    ## Fit and get ho mse for slr\n",
    "    knr = KNeighborsRegressor(5)\n",
    "    \n",
    "    knr.fit(car_tt[feature].values.reshape(-1,1),\n",
    "               car_tt.Sales.values)\n",
    "    \n",
    "    mses[2, i] = mean_squared_error(car_ho.Sales, knr.predict(car_ho[feature].values.reshape(-1,1)))\n",
    "    \n",
    "    ## Increase the counter by 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the avg cv mse for each model here\n",
    "np.mean(mses, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65c233",
   "metadata": {},
   "source": [
    "##### f. \"Best\" model.\n",
    "\n",
    "Based on the results of e. which model appears to have performed the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb78bb3",
   "metadata": {},
   "source": [
    "##### Write Answer Here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b729e",
   "metadata": {},
   "source": [
    "##### End of notebook\n",
    "\n",
    "We will not touch the test set in this notebook because we will continue to work with the carseats data set as we learn more regression model types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289172c8",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663f77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
