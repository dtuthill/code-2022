{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1503f647",
   "metadata": {},
   "source": [
    "# Problem Session 6\n",
    "## The Simpsons II\n",
    "\n",
    "In the second of two time series based problem sessions we build upon Problem Session 5. In particular, we will build more complicated forecasts on our Simpsons data.\n",
    "\n",
    "The problems in this notebook will cover the content covered in our `Time Series Forecasting` lectures including:\n",
    "- `Averaging and Smoothing`,\n",
    "- `Stationarity and Autocorrelation` and\n",
    "- `ARIMA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6da43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053cdc45",
   "metadata": {},
   "source": [
    "### The Simpsons\n",
    "\n",
    "##### 1. Refresher\n",
    "\n",
    "Recall that the data stored in `simpsons_imdb.csv` gives the IMDB rating for every episode of the Simpsons up to May 6, 2022. Our goal with this data set is to build a forecast that predicts the rating of an episode, given its number in the run of the Simpsons.\n",
    "\n",
    "Load `simpsons_imdb.csv` from the `Data` folder, then set aside the last season as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16523bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpsons = pd.read_csv(\"../Data/simpsons_imdb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "simps_train = simpsons.loc[simpsons.season != 33].copy()\n",
    "simps_test = simpsons.drop(simps_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea7185",
   "metadata": {},
   "source": [
    "Plot the training set data using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aef89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.scatter(range(1, len(simps_train)+1), simps_train.imdb_rating)\n",
    "\n",
    "plt.xlabel(\"Episode Number\", fontsize=16)\n",
    "plt.ylabel(\"IMDB Label\", fontsize=16)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a266324",
   "metadata": {},
   "source": [
    "In the previous problem session you built two baseline forecasts on these data. In this notebook we will build two of our more complex models.\n",
    "\n",
    "##### 2. A moving average model\n",
    "\n",
    "The first forecast we will try is the moving average forecast. \n",
    "\n",
    "Fill in the missing pieces of code below to run a time series cross-validation to find the moving average window size, $q$, that minimizes the average cross-validation mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f555794",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing things we need\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the 5-fold cross-validation object\n",
    "## set the test_size to 11\n",
    "cv = TimeSeriesSplit()\n",
    "\n",
    "## We'll try moving averages of size 2 to 30\n",
    "start = 2\n",
    "end = 31\n",
    "ma_mses = np.zeros((5, len(range(start, end))))\n",
    "\n",
    "\n",
    "## keeps count of our cv split\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(simps_train):\n",
    "    simps_tt = simps_train.loc[train_index]\n",
    "    simps_ho = simps_train.loc[test_index]\n",
    "    \n",
    "    ## keeps count of our MA choice\n",
    "    j = 0\n",
    "    for q in range(start, end):\n",
    "        ## Make the MA prediction here\n",
    "        pred = \n",
    "        \n",
    "        ## record the moving average mses\n",
    "        ma_mses[i,j] = mean_squared_error()\n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dc9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This should plot those MSEs\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.scatter(range(start,end), np.mean(ma_mses, axis=0))\n",
    "\n",
    "plt.xlabel(\"Window Size\", fontsize=16)\n",
    "plt.ylabel(\"Average CV MSE\", fontsize=16)\n",
    "\n",
    "plt.xticks(range(start, end, 3), fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The window size that minimized the avg. cv mse\",\n",
    "      \"was q =\", range(start,end)[np.argmin(np.mean(ma_mses, axis=0))],\".\"\n",
    "      \"It had a mean cv mse of\", np.round(np.min(np.mean(ma_mses, axis=0)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e909dac",
   "metadata": {},
   "source": [
    "##### 3. An exponential smoothing forecast\n",
    "\n",
    "Because this data has a trend, but not seasonality we will fit a double exponential smoothing model. For this we will want to find the best $\\alpha$ (The smoothing on the time series) and $\\beta$ (the smoothing on the trend component).\n",
    "\n",
    "Fill in the missing code chunks below to perform a grid search for the values of $\\alpha$ and $\\beta$ that minimize the average CV MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07076b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Holt from statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c85fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep track of the mses for each split, alpha, beta combo\n",
    "exp_mses = np.zeros((5, len(np.arange(0, 0.2, .01)), len(np.arange(0, 0.2, .01))))\n",
    "\n",
    "## keep track of split count\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(simps_train):\n",
    "    simps_tt = simps_train.loc[train_index]\n",
    "    simps_ho = simps_train.loc[test_index]\n",
    "    \n",
    "    ## keep track of alpha count\n",
    "    j = 0\n",
    "    for alpha in np.arange(0, 0.2, .01):\n",
    "        ## keep track of beta count\n",
    "        k = 0\n",
    "        for beta in np.arange(0, 0.2, .01):\n",
    "        \n",
    "            ## fit the exp smoothing model on the tt data\n",
    "            exp_smooth = \n",
    "            \n",
    "            ## record the mse of the forecast\n",
    "            exp_mses[i,j,k] = mean_squared_error()\n",
    "            \n",
    "            ## increase the beta count\n",
    "            k = k + 1\n",
    "        ## increase the alpha count    \n",
    "        j = j + 1\n",
    "    ## increase the split count\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This gives us the indices of the smallest\n",
    "## avg cv mse\n",
    "exp_ind = np.unravel_index(np.argmin(np.mean(exp_mses, axis=0), axis=None), np.mean(exp_mses, axis=0).shape)\n",
    "np.unravel_index(np.argmin(np.mean(exp_mses, axis=0), axis=None), np.mean(exp_mses, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e51ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The alpha and beta values that give a double exponential\",\n",
    "         \"smoothing model with lowest avg cv mse are\",\n",
    "         \"alpha = \", np.arange(0, 0.2, .01)[exp_ind[0]],\n",
    "         \"and beta = \", np.arange(0, 0.2, .01)[exp_ind[1]])\n",
    "\n",
    "print(\"This model had an avg cv mse of\",\n",
    "         np.round(np.mean(exp_mses, axis=0)[exp_ind],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b52b288",
   "metadata": {},
   "source": [
    "##### 4. An ARIMA model\n",
    "\n",
    "The final model we will build is an ARIMA model.\n",
    "\n",
    "##### a. Stationarity check\n",
    "\n",
    "First let's check if our series clearly breaks the stationarity assumption of ARIMA models. Make an autocorrelation plot of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import statsmodels.api as sm here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "\n",
    "## Make the autocorrelation plot here\n",
    "## set alpha=None, lags = 40 and ax=ax\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Simpsons IMDB rating ACF', fontsize=18)\n",
    "plt.ylabel(\"Autocorrelation\", fontsize=16)\n",
    "plt.xlabel(\"Lag\", fontsize=16)\n",
    "\n",
    "plt.ylim(-1.1,1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9dfd7",
   "metadata": {},
   "source": [
    "If you find that the ACF plot indicates that the time series is non-stationary, plot the ACF of the time series' first differences. Do these appear to be stationary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "\n",
    "## Make the autocorrelation plot here\n",
    "## set alpha=None, lags = 40 and ax=ax\n",
    "\n",
    "\n",
    "plt.title('Simpsons First Differences ACF', fontsize=18)\n",
    "plt.ylabel(\"Autocorrelation\", fontsize=16)\n",
    "plt.xlabel(\"Lag\", fontsize=16)\n",
    "\n",
    "plt.ylim(-1.1,1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35af28",
   "metadata": {},
   "source": [
    "##### b. Fitting the model\n",
    "\n",
    "From what we saw above we should set our $d$ value in the ARIMA model to $1$. This leaves us the $p$ and $q$ arguments to select. Fill in the missing code in the chunks below to perform a grid search that gives us the $p$ and $q$ values with the lowest avg. CV MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import SARIMAX here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we keep track of the mses for each split, p, q combo\n",
    "arima_mses = np.zeros((5, 4, 4))\n",
    "\n",
    "## the cv split counter\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(simps_train):\n",
    "    simps_tt = simps_train.loc[train_index]\n",
    "    simps_ho = simps_train.loc[test_index]\n",
    "    \n",
    "    ## the p counter\n",
    "    j = 0\n",
    "    for p in range(1,5):\n",
    "        ## the q counter\n",
    "        k = 0\n",
    "        for q in range(1,5):\n",
    "            ## Fit the SARIMAX model object, use a maxiter=500 in the .fit step\n",
    "            arima = \n",
    "            \n",
    "            ## record the mses for the forecast\n",
    "            arima_mses[i,j,k] = mean_squared_error()\n",
    "            \n",
    "            ## increase the q counter\n",
    "            k = k +1\n",
    "        ## increase the p counter\n",
    "        j = j + 1\n",
    "    ## increase the split counter\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the index of the lowest ARIMA mse\n",
    "arima_ind = np.unravel_index(np.argmin(np.mean(arima_mses, axis=0), axis=None), np.mean(arima_mses, axis=0).shape)\n",
    "np.unravel_index(np.argmin(np.mean(arima_mses, axis=0), axis=None), np.mean(arima_mses, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print it out\n",
    "print(\"The p and q values that give an ARIMA model\",\n",
    "         \"with lowest avg cv mse are\",\n",
    "         \"p = \", range(1,11)[arima_ind[0]],\n",
    "         \"and q = \", range(1,11)[arima_ind[1]])\n",
    "\n",
    "print(\"This model had an avg cv mse of\",\n",
    "         np.round(np.mean(arima_mses, axis=0)[arima_ind],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a63bd",
   "metadata": {},
   "source": [
    "##### 5. Forecast comparison\n",
    "\n",
    "We have now fit 3 separate forecast types on these data in addition to the two baseline forecasts from `Problem Session 5`. Run the code chunk below to get the mean CV MSE for those two baseline forecasts.\n",
    "\n",
    "Which forecast has the best performance with respect to CV MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "base_mses = np.zeros((2, 5))\n",
    "\n",
    "j = 0\n",
    "for train_index, test_index in cv.split(simps_train):\n",
    "    simps_tt = simps_train.loc[train_index]\n",
    "    simps_ho = simps_train.loc[test_index]\n",
    "    \n",
    "    ## baseline 1\n",
    "    pred1 = simps_tt.imdb_rating.mean()*np.ones(len(simps_ho))\n",
    "    \n",
    "    base_mses[0,j] = mean_squared_error(simps_ho.imdb_rating.values, pred1)\n",
    "    \n",
    "    ## baseline 2\n",
    "    slr = LinearRegression()\n",
    "\n",
    "    slr.fit(np.arange(1, len(simps_tt)+1).reshape(-1,1), simps_tt.imdb_rating.values)\n",
    "    \n",
    "    pred2 = slr.predict(np.arange(len(simps_tt)+1, len(simps_tt) + len(simps_ho) + 1).reshape(-1,1))\n",
    "    \n",
    "    base_mses[1,j] = mean_squared_error(simps_ho.imdb_rating.values, pred2)\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f57e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean CV MSE for the average baseline is\", \n",
    "          np.round(np.mean(base_mses[0,:]), 3))\n",
    "print(\"The mean CV MSE for the trend baseline is\",\n",
    "          np.round(np.mean(base_mses[1,:]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee038523",
   "metadata": {},
   "source": [
    "##### 6. Test set\n",
    "\n",
    "Plot the best forecast with the training and test data. What is the MSE of the forecast on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b94880",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the forecast here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b3b39",
   "metadata": {},
   "source": [
    "Feel free to spend any extra time you have playing around with different forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b83887",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a427da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
