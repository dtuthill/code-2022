{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0cddb2",
   "metadata": {},
   "source": [
    "# Problem Session 1\n",
    "## Data Collection\n",
    "\n",
    "The problems contained in this notebook relate to the concepts covered in the `Data Collection` lecture notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e4651",
   "metadata": {},
   "source": [
    "##### 1. Searching repositories/competition sites\n",
    "\n",
    "You are interested in a project that looks at the opening and closing prices of the SNP500 stock index. Using one of the data repository or data competition sites discussed in `2. Data Repositories.ipynb` or `3. Data Competition Sites.ipynb` find a data file that contains the closing and opening values going back to 1928."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321402b9",
   "metadata": {},
   "source": [
    "##### Make any notes or code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67705ad7",
   "metadata": {},
   "source": [
    "##### 2. Scraping college football data I\n",
    "\n",
    "Using `BeautifulSoup` scrape the data contained in the \"110 Years\" table at this link, <a href=\"https://www.sports-reference.com/cfb/schools/ohio-state/\">https://www.sports-reference.com/cfb/schools/ohio-state/</a>, and record the values stored in the \"Coaches\" columns in a list. Who had the most years as the Ohio State University football coach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75071d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d32df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be682f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99568916",
   "metadata": {},
   "source": [
    "##### 3. Scraping college football data II\n",
    "\n",
    "Use `BeautifulSoup` to scrape the \"Defense & Fumbles\" table. Create a `DataFrame` containing the name of the player, the number of games that player played (stored under \"G\"), the total number of tackles they had (stored under \"Tot\"), and the total number sacks (stored under \"Sk\").  Who has the most tackles per game? Who had the highest fraction of their tackles as a sack?\n",
    "\n",
    "##### Hint: This stack overflow post could be useful, <a href=\"https://stackoverflow.com/questions/33138937/how-to-find-all-comments-with-beautiful-soup\">https://stackoverflow.com/questions/33138937/how-to-find-all-comments-with-beautiful-soup</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aed4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e497fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0132965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fb75d9",
   "metadata": {},
   "source": [
    "##### 4. Plotting <a href=\"https://www.imdb.com/title/tt0096697/?ref_=nv_sr_srsg_0\">\"The Simpsons\" IMDB</a> ratings\n",
    "\n",
    "In this problem we will work through scraping the Simpsons episode ratings on IMDB using a Python wrapper for the IMDB API called `Cinemagoer` (formerly called `IMDBpy`). Here is a link to the documentation for this package, <a href=\"https://buildmedia.readthedocs.org/media/pdf/imdbpy/latest/imdbpy.pdf\">https://buildmedia.readthedocs.org/media/pdf/imdbpy/latest/imdbpy.pdf</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ef320",
   "metadata": {},
   "source": [
    "##### a. Installation. \n",
    "\n",
    "Go to the documentation linked to above and look for installation instructions. Install the `Cinemagoer` package onto your machine. Once you think you have it installed you should be able to run the code chunks below.\n",
    "\n",
    "<i>Note, only one person in your group needs to have installed the package on their laptop in order to continue. Do not get hung up on the installation step during the problem session</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72f92a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "418f4600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022.02.11\n"
     ]
    }
   ],
   "source": [
    "print(imdb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8cc88",
   "metadata": {},
   "source": [
    "##### b. Making a `Cinemagoer` object\n",
    "\n",
    "Creating a `Cinemagoer` object is what allows us to request data from IMDB. Use the Example at the start of chapter 3 (page 7) of the documentation to learn how to create a `Cinemagoer` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a99578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d125a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727df873",
   "metadata": {},
   "source": [
    "##### c. Finding \"The Simpsons\" `Movie id`.\n",
    "\n",
    "In order to get rating information from each episode of \"The Simpsons\" we need its unique identifier, its `Movie id`.\n",
    "\n",
    "We can find that using the `search_movie` function of the `Cinemagoer` class.\n",
    "\n",
    "Search the documentation for how to use `search_movie` to search for `\"The Simpsons\" (1989)` using the search term `'simpsons'`. A `list` should be returned. When you find the entry that corresponds to `\"The Simpsons\" (1989)` store a string of the id in a variable called `simpsons_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6980f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be188bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43f9b4",
   "metadata": {},
   "source": [
    "##### d. Using `get_movie`\n",
    "\n",
    "Search the documentation for `get_movie` to see how we can get \"The Simpsons\" result using the `simpsons_id` that we found in the last problem. Store the result in a variable called `simpsons`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01fa097",
   "metadata": {},
   "source": [
    "###### e. Getting data from each of the over 700 episodes.\n",
    "\n",
    "Search the documentation for `update(series, 'episodes')` to see how to return the IMDB data for each episode and have it stored in your `simpsons` variable.\n",
    "\n",
    "<i>Note: Do not worry if this seems to take a long time, because \"The Simpsons\" has over 700 episodes a lot of calls have to be made to the API.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c59bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b82780",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2947e",
   "metadata": {},
   "source": [
    "##### f. Looking at the `episodes`. \n",
    "\n",
    "What is kind of Python object is returned when you run `simpsons['episodes']`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fea0b3",
   "metadata": {},
   "source": [
    "##### g. How to find the IMDB rating?\n",
    "\n",
    "Look at the `keys` for an episode of your choice using `.keys()`, which one seems to contain the IMDB rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4366c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb28605",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dad3eb",
   "metadata": {},
   "source": [
    "##### h. Getting the ratings for each episode.\n",
    "\n",
    "Write some python code to store each episode's rating in a list.\n",
    "\n",
    "<i>Note: Newer episodes may not yet have a rating, so you will have to account for that in your code.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ef85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da947ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c65e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7259be",
   "metadata": {},
   "source": [
    "##### i. Plot the ratings over time.\n",
    "\n",
    "Use `matplotlib` to plot the ratings over time to see how reception of the show has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69eebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebbd05e",
   "metadata": {},
   "source": [
    "##### 5. [Slightly More Advanced Question] Scraping 538 politics\n",
    "\n",
    "You are hired by a clickbait creation company that wants to completely eliminate the need for writers by creating a clickbait generation algorithm. You have been tasked with scraping article data from 538's Politics beat that someone else on the company's team will use in the generation algorithm.\n",
    "\n",
    "##### a. Titles and urls\n",
    "\n",
    "To start, write a script using `BeautifulSoup` to scrape the post titles and urls for the first five pages of results for the \"Politics\" tab on <a href=\"https://fivethirtyeight.com\">https://fivethirtyeight.com</a>.\n",
    "    \n",
    "<i>Hint: A good starting point would be to explore <a href=\"https://fivethirtyeight.com/politics/\">https://fivethirtyeight.com/politics/</a>, and cross-reference what we did in the notebook `5. Web Scraping with BeautifulSoup.ipynb`.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f91f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68188284",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0cac82",
   "metadata": {},
   "source": [
    "##### b. Identifying written posts or \"features\"\n",
    "\n",
    "Not all of the posts are written features, some are video content. Write a script that will get rid of the video posts and leave only the written features.\n",
    "\n",
    "<i>Hint: look at the hrefs of each post.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85afd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51090112",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6218e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ada65f",
   "metadata": {},
   "source": [
    "##### c. Scraping the text\n",
    "\n",
    "Write a script that will take the href from one of these feature posts and return the written text of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfdcd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6af776",
   "metadata": {},
   "source": [
    "##### d. Scrape all the feature texts\n",
    "\n",
    "Write a loop to scrape all of the text for the features you just pulled, store the results in a list. Each entry in the list should be the entire text of a single feature. Remember to sleep between url requests, 3 seconds is a reasonable amount of time between each pull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fb738",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bc8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f2c9d",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12dc74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
