{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f46ba6",
   "metadata": {},
   "source": [
    "# Problem Session 9\n",
    "## Classifying Cancer III\n",
    "\n",
    "In this notebook you continue to work with the cancer data set that can be found here, <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29</a>. \n",
    "\n",
    "\n",
    "The problems in this notebook will cover the content covered in some of our `Classification`, `Dimension Reduction` and our `Ensemble Learning` notebooks. In particular we will cover content touched on in:\n",
    "- `Classification/Support Vector Machines`\n",
    "- `Classification/Decision Trees`,\n",
    "- `Ensemble Learning/Random Forests` and\n",
    "- `Dimension Reduction/Principal Components Analysis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b080701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057f4e6",
   "metadata": {},
   "source": [
    "##### 1. Load the data.\n",
    "\n",
    "The data for this problem is stored in `sklearn`, here is the documentation page for that, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\">https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html</a>.\n",
    "\n",
    "Run this code chunk to load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f140ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loads the data from sklearn \n",
    "cancer = load_breast_cancer(as_frame=True)\n",
    "\n",
    "## the 'data' entry contains the features\n",
    "X = cancer['data']\n",
    "\n",
    "## the 'target' entry contains what we would like to predict\n",
    "y = cancer['target']\n",
    "\n",
    "## Chaning the labels around\n",
    "y = -y + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.copy(), y.copy(),\n",
    "                                                       shuffle=True,\n",
    "                                                       random_state=214,\n",
    "                                                       stratify=y,\n",
    "                                                       test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ad019",
   "metadata": {},
   "source": [
    "##### 2. Refresher\n",
    "\n",
    "Take a few minutes to remind yourselves about the cancer classification problem by reviewing `Problem Session 7` and `Problem Session 8` as needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26ecf4",
   "metadata": {},
   "source": [
    "##### 3. Support Vector Classifer\n",
    "\n",
    "Fill in the missing code below to find the average CV TPR, FPR and precision for a support vector classifier, `SVC` in `sklearn`, on the cancer data. Use a radial basis function kernel.\n",
    "\n",
    "Remember to scale the data before fitting the support vector machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import things from sklearn here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tprs = np.zeros(5)\n",
    "svc_fprs = np.zeros(5)\n",
    "svc_precs = np.zeros(5)\n",
    "\n",
    "\n",
    "## make the kfold object\n",
    "kfold = \n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train, y_train):\n",
    "    X_tt = X_train.iloc[train_index,:]\n",
    "    y_tt = y_train.iloc[train_index]\n",
    "    X_ho = X_train.iloc[test_index,:]\n",
    "    y_ho = y_train.iloc[test_index]\n",
    "    \n",
    "    ## Make the SVC pipeline here\n",
    "    \n",
    "    \n",
    "    ## fit the pipeline\n",
    "    pipe\n",
    "    \n",
    "    ## predict on the holdout set\n",
    "    pred = pipe\n",
    "    \n",
    "    \n",
    "    conf_mat = confusion_matrix(y_ho, pred)\n",
    "    \n",
    "    svc_tprs[i] = conf_mat[1,1]/(conf_mat[1,0] + conf_mat[1,1])\n",
    "    svc_fprs[i] = conf_mat[0,1]/(conf_mat[0,0] + conf_mat[0,1])\n",
    "    svc_precs[i] = precision_score(y_ho, pred)\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This prints out the performances for this model\n",
    "print(\"The AVG. CV. TPR is\", np.round(np.mean(svc_tprs),4))\n",
    "print(\"The AVG. CV. FPR is\", np.round(np.mean(svc_fprs),4))\n",
    "print(\"The AVG. CV. precision is\", np.round(np.mean(svc_precs),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23938b14",
   "metadata": {},
   "source": [
    "##### 4. Optimizing explained variance for SVM\n",
    "\n",
    "It is possible that we could improve the performance of our support vector classifier by preprocessing the data with PCA first.\n",
    "\n",
    "Fill in the missing code in the chunks below to tune the fraction of total explained variance used in the PCA step.\n",
    "\n",
    "What are the explained variance ratios with the best average CV TPR, FPR and precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb671c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs = np.arange(.01, 1, .01)\n",
    "\n",
    "pca_tprs = np.zeros((5, len(fracs)))\n",
    "pca_fprs = np.zeros((5, len(fracs)))\n",
    "pca_precs = np.zeros((5, len(fracs)))\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train, y_train):\n",
    "    X_tt = X_train.iloc[train_index, :]\n",
    "    X_ho = X_train.iloc[test_index, :]\n",
    "    y_tt = y_train.iloc[train_index]\n",
    "    y_ho = y_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for frac in fracs:\n",
    "        ## Make the pipeline including PCA here\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Fit the pipeline\n",
    "        svc_pipe\n",
    "        \n",
    "        \n",
    "        ## Predict on the holdout set\n",
    "        pred = \n",
    "\n",
    "        ## record the precision score\n",
    "        pca_precs[i,j] = \n",
    "        \n",
    "        ## get the confusion matrix\n",
    "        conf_mat = \n",
    "        \n",
    "        ## Calculate TPR and FPR\n",
    "        pca_tprs[i,j] = \n",
    "        pca_fprs[i,j] = \n",
    "        j = j + 1\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f8c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prints the performance for you\n",
    "print(\"TPR\")\n",
    "print(\"==============================\")\n",
    "print(\"The explained variance ration with the highest avg. cv TPR was\",\n",
    "          fracs[np.argmax(np.mean(pca_tprs, axis=0))])\n",
    "print(\"This feature produced a model with avg. cv. TPR of\",np.round(np.max(np.mean(pca_tprs, axis=0)),4))\n",
    "print()\n",
    "\n",
    "print(\"FPR\")\n",
    "print(\"==============================\")\n",
    "print(\"The explained variance ration with the lowest avg. cv FPR was\",\n",
    "          fracs[np.argmin(np.mean(pca_fprs, axis=0))])\n",
    "print(\"This feature produced a model with avg. cv. FPR of\",np.round(np.min(np.mean(pca_fprs, axis=0)),4))\n",
    "print()\n",
    "\n",
    "print(\"Precision\")\n",
    "print(\"==============================\")\n",
    "print(\"The explained variance ration with the highest avg. cv Precision was\",\n",
    "          fracs[np.argmax(np.mean(pca_precs, axis=0))])\n",
    "print(\"This feature produced a model with avg. cv. Precision of\",np.round(np.max(np.mean(pca_precs, axis=0)),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e792c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1, figsize=(12,10), sharex=True)\n",
    "\n",
    "## TPR\n",
    "ax[0].plot(, '-o')\n",
    "ax[0].set_ylabel(\"True Positive Rate\", fontsize=16)\n",
    "\n",
    "## FPR\n",
    "ax[1].plot(, '-o')\n",
    "ax[1].set_ylabel(\"False Positive Rate\", fontsize=16)\n",
    "\n",
    "## Precs\n",
    "ax[2].plot(, '-o')\n",
    "ax[2].set_ylabel(\"Precision\", fontsize=16)\n",
    "\n",
    "ax[2].set_xlabel(\"Explained Variance Ratio\", fontsize=16)\n",
    "ax[2].set_xticks(np.arange(0,1.1,.1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ff59c",
   "metadata": {},
   "source": [
    "##### 5. Planting  a tree\n",
    "\n",
    "Using `sklearn`'s `DecisionTreeClassifier` to train a decision tree on the training data. For this tree use all of the default `sklearn` settings, that is do not pass any arguments to `DecisionTreeClassifier` when you define the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import DecisionTreeClassifier here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc239a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define and fit the model here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the confusion matrix on the training set?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47391f3",
   "metadata": {},
   "source": [
    "After inserting the variable name for your model, run the following snippet of code. This code will plot the decision tree that you just fit and save it in an image file labeled `cancer_dec_tree.png`. This file will be located in the `Problem Sets` folder in your repository. Open the image outside of the jupyter notebook to get a better look at it. \n",
    "\n",
    "<i>What are some of the sample sizes in the terminal nodes? Terminal nodes are those nodes with nowhere to go. In the image they will be a box without any arrows exiting them.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9dde16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(34,44))\n",
    "\n",
    "## Place the name of your  model below\n",
    "out = plot_tree(YOUR_NAME_HERE, filled=True, feature_names = X_train.columns)\n",
    "\n",
    "\n",
    "plt.savefig(\"cancer_dec_tree.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31108f56",
   "metadata": {},
   "source": [
    "##### 6. Assessing overfitting\n",
    "\n",
    "Run the default model through 5-fold cross-validation, record the accuracy for the predictions on each cross-validation split's training <b>and</b> holdout set. Compare these two sets of accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import accuracy here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b361691",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4124)\n",
    "\n",
    "train_accs = np.zeros(5)\n",
    "holdout_accs = np.zeros(5)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train, y_train):\n",
    "    X_tt = X_train.iloc[train_index]\n",
    "    y_tt = y_train.iloc[train_index]\n",
    "    X_ho = X_train.iloc[test_index]\n",
    "    y_ho = y_train.iloc[test_index]\n",
    "    \n",
    "    ## Make and fit the decision tree here\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Record the training set accuracy\n",
    "    train_accs[i] = \n",
    "    \n",
    "    ## Record the holdout set accuracy\n",
    "    holdout_accs[i] = \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.scatter(range(1,6), train_accs, s=100, c='k', label='CV Training Set')\n",
    "plt.scatter(range(1,6), holdout_accs, s=100, c='white', edgecolor='red', label='CV Holdout Set')\n",
    "\n",
    "plt.xlabel(\"Cross-Validation Split\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.ylim(.85,1.01)\n",
    "\n",
    "plt.legend(loc=4,fontsize=16)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(range(1,6),fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb28a83",
   "metadata": {},
   "source": [
    "<i>Based on the past two questions, does it look like the default decision tree is overfitting on the training data?</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21787b5b",
   "metadata": {},
   "source": [
    "##### 7. Hyperparameter tuning\n",
    "\n",
    "Use cross-validation to find the optimal value for `max_depth` for TPR, FPR and precision. Place a `random_state =` argument when you define your `DecisionTreeClassifier`. If you are interested in what this does see the documentation here <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9865374",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(1,9)\n",
    "\n",
    "tree_tprs = np.zeros((5, len(depths)))\n",
    "tree_fprs = np.zeros((5, len(depths)))\n",
    "tree_precs = np.zeros((5, len(depths)))\n",
    "\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train, y_train):\n",
    "    X_tt = X_train.iloc[train_index]\n",
    "    y_tt = y_train.iloc[train_index]\n",
    "    X_ho = X_train.iloc[test_index]\n",
    "    y_ho = y_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for depth in depths:\n",
    "        ## Make the tree\n",
    "        tree = \n",
    "        \n",
    "        ## Fit the tree\n",
    "        tree\n",
    "\n",
    "        ## Get the prediction on the holdout set\n",
    "        pred = \n",
    "\n",
    "        ## This records the performances for you\n",
    "        tree_precs[i,j] = precision_score(y_ho, pred)        \n",
    "        \n",
    "        conf_mat = confusion_matrix(y_ho, pred)\n",
    "        \n",
    "        tree_tprs[i,j] = conf_mat[1,1]/(conf_mat[1,0] + conf_mat[1,1])\n",
    "        tree_fprs[i,j] = conf_mat[0,1]/(conf_mat[0,0] + conf_mat[0,1])\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7654af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the avg. CV. performances here\n",
    "fig,ax = plt.subplots(3,1, figsize=(12,10), sharex=True)\n",
    "\n",
    "## TPR\n",
    "ax[0].plot(depths,  , '-o')\n",
    "ax[0].set_ylabel(\"True Positive Rate\", fontsize=16)\n",
    "\n",
    "## FPR\n",
    "ax[1].plot(depths,  , '-o')\n",
    "ax[1].set_ylabel(\"False Positive Rate\", fontsize=16)\n",
    "\n",
    "## Precs\n",
    "ax[2].plot(depths,  , '-o')\n",
    "ax[2].set_ylabel(\"Precision\", fontsize=16)\n",
    "\n",
    "ax[2].set_xlabel(\"Maximum Depth\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24497b",
   "metadata": {},
   "source": [
    "<i>Choose a depth based on the plots above</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b3858",
   "metadata": {},
   "source": [
    "#####  8. Random Forest\n",
    "\n",
    "Using your answers to the previous question you will optimize the hyperparameter `n_estimators` to identify a random forest classifier with a good balance between TPR, FPR and precision.\n",
    "\n",
    "Use cross-validation to find the value of `n_estimators` from `[50, 100, 250, 500, 1000, 1500, 2000]` that gives the best performance for either metric. Set `max_samples=200` in your `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ad534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c10e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_trees = [50, 100, 250, 500, 1000, 1500, 2000]\n",
    "\n",
    "rf_tprs = np.zeros((5, len(num_of_trees)))\n",
    "rf_fprs = np.zeros((5, len(num_of_trees)))\n",
    "rf_precs = np.zeros((5, len(num_of_trees)))\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train, y_train):\n",
    "    X_tt = X_train.iloc[train_index]\n",
    "    y_tt = y_train.iloc[train_index]\n",
    "    X_ho = X_train.iloc[test_index]\n",
    "    y_ho = y_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for num_trees in num_of_trees:\n",
    "        ## Build the random forest here\n",
    "        rf = \n",
    "        \n",
    "        ## fit and predict\n",
    "        rf\n",
    "        pred = \n",
    "        \n",
    "        ## This records the performances for you\n",
    "        conf_mat = confusion_matrix(y_ho, pred)\n",
    "                \n",
    "        rf_precs[i,j] = precision_score(y_ho, pred)\n",
    "        rf_tprs[i,j] = conf_mat[1,1]/(conf_mat[1,0] + conf_mat[1,1])\n",
    "        rf_fprs[i,j] = conf_mat[0,1]/(conf_mat[0,0] + conf_mat[0,1])\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in the missing data to plot\n",
    "fig,ax = plt.subplots(3,1, figsize=(12,10), sharex=True)\n",
    "\n",
    "## TPR\n",
    "ax[0].plot(range(len(num_of_trees)), , '-o')\n",
    "ax[0].set_ylabel(\"True Positive Rate\", fontsize=16)\n",
    "\n",
    "## FPR\n",
    "ax[1].plot(range(len(num_of_trees)), , '-o')\n",
    "ax[1].set_ylabel(\"False Positive Rate\", fontsize=16)\n",
    "\n",
    "## Precs\n",
    "ax[2].plot(range(len(num_of_trees)), , '-o')\n",
    "ax[2].set_ylabel(\"Precision\", fontsize=16)\n",
    "\n",
    "ax[2].set_xlabel(\"Number of Decision Trees\", fontsize=16)\n",
    "ax[2].set_xticks(range(len(num_of_trees)))\n",
    "ax[2].set_xticklabels(num_of_trees)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02964ffe",
   "metadata": {},
   "source": [
    "#####  9. Feature Importances\n",
    "\n",
    "Use `RandomForestClassifier`'s `feature_importances_` method to examine which features are most important in determining whether or not a tumor is malignant or benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make and fit the model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a data frame of the feature importances\n",
    "pd.DataFrame(,\n",
    "                index=X_train.columns,\n",
    "                columns=['feature_importance_score']).sort_values('feature_importance_score', \n",
    "                                                                  ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677bba45",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da9bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
