{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d627d2ef",
   "metadata": {},
   "source": [
    "# Fall Problem Session 10\n",
    "## Classifying Pumpkin Seeds IV\n",
    "\n",
    "In this notebook you continue to work with the pumpkin seed data from <a href=\"https://link.springer.com/article/10.1007/s10722-021-01226-0\">The use of machine learning methods in classification of pumpkin seeds (Cucurbita pepo L.)</a> by Koklu, Sarigil and Ozbek (2021). By the end of the notebook you will select a final model for this data and check its performance on the test set.\n",
    "\n",
    "The problems in this notebook will cover the content covered in some of our `Classification`, `Dimension Reduction` and our `Ensemble Learning` notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aaeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing packages you'll probably use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f48766",
   "metadata": {},
   "source": [
    "#### 1. Load and prepare the data and refresh your memory\n",
    "\n",
    "Run the code below in order to:\n",
    "\n",
    "- Load the data stored in `Pumpkin_Seeds_Dataset.xlsx` in the `Data` folder,\n",
    "- Create a column `y` where `y=1` if `Class=Ürgüp Sivrisi` and `y=0` if `Class=Çerçevelik` and\n",
    "- Make a train test split setting $10\\%$ of the data aside as a test set.\n",
    "\n",
    "If you need to refresh your memory on these data and the problem, you may want to look at a small subset of the data, look back on `Fall Problem Session 7`, `Fall Problem Session 8` and `Fall Problem Session 9` and/or browse Figure 5 and Table 1 of this paper, <a href=\"pumpkin_seed_paper.pdf\">pumpkin_seed_paper.pdf</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7bc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the data\n",
    "seeds = pd.read_excel(\"../Data/Pumpkin_Seeds_Dataset.xlsx\")\n",
    "\n",
    "## make target column y\n",
    "seeds['y'] = 0\n",
    "\n",
    "seeds.loc[seeds.Class=='Ürgüp Sivrisi', 'y']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b23b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making stratified train test split\n",
    "seeds_train, seeds_test = train_test_split(seeds.copy(),\n",
    "                                              shuffle=True,\n",
    "                                              random_state=123,\n",
    "                                              test_size=.1,\n",
    "                                              stratify=seeds.y.values)\n",
    "\n",
    "## recording the features in a list for model building\n",
    "features = seeds_train.columns[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb4262",
   "metadata": {},
   "source": [
    "#### 2. An AdaBoost classifier\n",
    "\n",
    "\n",
    "##### a.\n",
    "\n",
    "Import the adaptive boosting classifier model and decision tree models from `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5193cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import adaboost\n",
    "from sklearn.\n",
    "\n",
    "## import decision tree\n",
    "from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4cd9a4",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Using either a `for` loop or `GridSearchCV` determine the optimal value for `n_estimators` for an `AdaBoostClassifier` using a `DecisionTreeClassifier` with `max_depth=2` as its base estimator. Set the `learning_rate=1` in the `AdaBoostClassifier`. \n",
    "\n",
    "Plot the average cross-validation accuracy against the value of `n_estimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d801aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import what you need for the cross-validation here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the cross-validation here\n",
    "\n",
    "## Consider these for the number of estimators.\n",
    "n_estimators = range(1,26)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d451125",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot()\n",
    "\n",
    "plt.xlabel(\"n_estimators\", fontsize=18)\n",
    "plt.ylabel(\"Avg. CV Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57dd8a6",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "How many decision trees do you choose for your adaptive boosting classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec03b5",
   "metadata": {},
   "source": [
    "##### Write your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676373a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d4a9a48",
   "metadata": {},
   "source": [
    "#### 3. A voting classifier\n",
    "\n",
    "In this problem you will explore making a voting classifier for these data.\n",
    "\n",
    "##### a.\n",
    "\n",
    "Recall that a voting classifier is a classification model where the prediction for a particular observation is an average of the predictions from a group of classifiers.\n",
    "\n",
    "As a first step to building a voting classifier review the best models you have built through `Fall Problem Session 7` to `Fall Problem Session 9`:\n",
    "\n",
    "- A logistic regression model regressing `y` on a single feature,\n",
    "- A $k$ nearest neighbors model using PCA processed features as input,\n",
    "- A support vector machine model,\n",
    "- A quadratic discriminant analysis model,\n",
    "- A random forest model and, in this notebook,\n",
    "- An adaptive boosting model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7821ee",
   "metadata": {},
   "source": [
    "##### b. \n",
    "\n",
    "We should only expect a voting classifier to perform better than its constituent models when there is not a lot of overlap in the observations that each model incorrectly classifies. For example, if most of your models are incorrect about a particular observation, then the voter model will also be incorrect for that observation.\n",
    "\n",
    "As an initial investigation for the voter model:\n",
    "\n",
    "- Make a validation set of size 100 from the training data,\n",
    "- Fill in the missing pieces of code to fit all of the models you have considered up to this point on the training set from the validation split you just made,\n",
    "- Get predictions for all of these models on the validation set and\n",
    "- Then run the `plt.imshow` code chunk to show where these models were incorrect on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568fbab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First import everything we'll need\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78520a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the validation split\n",
    "seeds_tt, seeds_val = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de012e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### make all the model objects ####\n",
    "\n",
    "## Adaptive Boosting\n",
    "## fill in the parameters you found above\n",
    "ada_boost = AdaBoostClassifier()\n",
    "\n",
    "## K nearest neighbors with PCA pre-processing\n",
    "knn = Pipeline([('scale', StandardScaler()),\n",
    "                   ('pca', PCA(3)),\n",
    "                   ('knn', KNeighborsClassifier(38))])\n",
    "\n",
    "## QDA\n",
    "qda = Pipeline([('scale', StandardScaler()),\n",
    "                    ('qda', QuadraticDiscriminantAnalysis())])\n",
    "\n",
    "## Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "## Support vector machine\n",
    "svm = Pipeline([('scale', StandardScaler()),\n",
    "                   ('svm', SVC(C = 30))])\n",
    "\n",
    "## Random Forest\n",
    "rf = RandomForestClassifier(max_depth=8, \n",
    "                            n_estimators=500)\n",
    "\n",
    "\n",
    "##### Fit all of the models #####\n",
    "## complete the adaboost code\n",
    "ada_boost\n",
    "knn.fit(seeds_tt[features], seeds_tt.y)\n",
    "qda.fit(seeds_tt[features], seeds_tt.y)\n",
    "log_reg.fit(seeds_tt['Aspect_Ration'].values.reshape(-1,1), seeds_tt.y)\n",
    "svm.fit(seeds_tt[features], seeds_tt.y)\n",
    "rf.fit(seeds_tt[features], seeds_tt.y)\n",
    "  \n",
    "    \n",
    "##### Get predictions on the validation set #####\n",
    "## complete the adaboost code\n",
    "ada_pred = \n",
    "knn_pred = knn.predict(seeds_val[features])\n",
    "qda_pred = qda.predict(seeds_val[features])\n",
    "log_pred = log_reg.predict(seeds_val['Aspect_Ration'].values.reshape(-1,1))\n",
    "svm_pred = svm.predict(seeds_val[features])\n",
    "rf_pred = rf.predict(seeds_val[features])\n",
    "\n",
    "\n",
    "##### This records what observations in the validation set\n",
    "##### Each model got wrong\n",
    "wrongs = np.zeros((6, len(seeds_val)))\n",
    "                ## pred != y.values produces an array of Trues and Falses for where\n",
    "                ## an entry is true if the prediction does not equal the actual\n",
    "                ## and false if the prediction does equal the actual\n",
    "wrongs[0,:] = ada_pred != seeds_val.y.values\n",
    "wrongs[1,:] = knn_pred != seeds_val.y.values\n",
    "wrongs[2,:] = qda_pred != seeds_val.y.values\n",
    "wrongs[3,:] = log_pred != seeds_val.y.values\n",
    "wrongs[4,:] = svm_pred != seeds_val.y.values\n",
    "wrongs[5,:] = rf_pred != seeds_val.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This makes a heat map of where each model was incorrect\n",
    "### A bright spot indicates the model was wrong for that observation\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "## docs: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html\n",
    "plt.imshow(wrongs)\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([0,1,2,3,4,5], \n",
    "              [\"AdaBoost\", \"KNN\", \"QDA\", \"Log. Reg.\", \"SVM\", \"R.F.\"],\n",
    "              fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd84b2f3",
   "metadata": {},
   "source": [
    "##### c. \n",
    "\n",
    "Look at the heat map you just made. Each square in this map indicates whether a model (the rows) got a particular observation (the columns) incorrect. A bright square indicates a model was incorrect for that observation, a dark square indicates that it was correct.\n",
    "\n",
    "Based on this investigatory heat map do you think that a voter model made up of these models would do better than any one model? Why or Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f674cea",
   "metadata": {},
   "source": [
    "##### Write your thoughts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50615f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52bf0b13",
   "metadata": {},
   "source": [
    "##### d. \n",
    "\n",
    "Make a voter model using all of the models considered in <i>b.</i> above. Train it on the training set from the validation split. Then compare the accuracies of all models on the validation set to the voter model's validation accuracy. The code has been started for you because the logistic regression model required particular preprocessing in order to be fed into the voter model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the VotingClassifier here\n",
    "from sklearn.\n",
    "\n",
    "## import the rest of what we'll need\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function will only return the 'Aspect_Ration' column\n",
    "def get_single_feature(df):\n",
    "    return df['Aspect_Ration'].values.reshape(-1,1)\n",
    "\n",
    "## fill in the rest of the VotingClassifier\n",
    "vote = VotingClassifier([('log_reg', Pipeline([('get_column', FunctionTransformer(get_single_feature)),\n",
    "                                                 ('log_reg', LogisticRegression())])),\n",
    "                            ])\n",
    "\n",
    "\n",
    "## fit the model\n",
    "\n",
    "\n",
    "## get the voting model prediction\n",
    "\n",
    "\n",
    "\n",
    "## Here we record all of the accuracies on the validation set\n",
    "vote_acc = accuracy_score(seeds_val.y, vote_pred)\n",
    "log_acc = accuracy_score(seeds_val.y, log_pred)\n",
    "knn_acc = accuracy_score(seeds_val.y, knn_pred)\n",
    "ada_acc = accuracy_score(seeds_val.y, ada_pred)\n",
    "qda_acc = accuracy_score(seeds_val.y, qda_pred)\n",
    "svm_acc = accuracy_score(seeds_val.y, svm_pred)\n",
    "rf_acc = accuracy_score(seeds_val.y, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prints them all out for you\n",
    "print(\"Logistic regression validataion set accuracy = \", np.round(log_acc*100, 2))\n",
    "print(\"KNN validataion set accuracy = \", np.round(knn_acc*100, 2))\n",
    "print(\"QDA validataion set accuracy = \", np.round(qda_acc*100, 2))\n",
    "print(\"SVM validataion set accuracy = \", np.round(svm_acc*100, 2))\n",
    "print(\"Random forest validataion set accuracy = \", np.round(rf_acc*100, 2))\n",
    "print(\"Adaboost validataion set accuracy = \", np.round(ada_acc*100, 2))\n",
    "print(\"=========================================\")\n",
    "print(\"Voter model validataion set accuracy = \", np.round(vote_acc*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2584aa9e",
   "metadata": {},
   "source": [
    "#### 4. Choosing a final model\n",
    "\n",
    "##### a.\n",
    "\n",
    "Fill in the missing code below to run each of the seven models you just considered through 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the appropriate kfold object\n",
    "from sklearn.model_selection import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the number of CV splits\n",
    "n_splits = 10\n",
    "\n",
    "## complete the kfold object here\n",
    "kfold = \n",
    "\n",
    "## this will hold the accuracies for each split\n",
    "cv_accs = np.zeros((n_splits, 7))\n",
    "\n",
    "\n",
    "i = 0\n",
    "## loop through the cross-validation splits\n",
    "for train_index, test_index in kfold.split(seeds_train, seeds_train.y):\n",
    "    ## make the train holdout split\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    ### Making the model objects ###\n",
    "    \n",
    "    ## Adaptive Boosting\n",
    "    ## fill in the parameters you found above\n",
    "    ada_boost = AdaBoostClassifier()\n",
    "\n",
    "    ## K nearest neighbors with PCA pre-processing\n",
    "    knn = Pipeline([('scale', StandardScaler()),\n",
    "                       ('pca', PCA(3)),\n",
    "                       ('knn', KNeighborsClassifier(38))])\n",
    "\n",
    "    ## QDA\n",
    "    qda = Pipeline([('scale', StandardScaler()),\n",
    "                        ('qda', QuadraticDiscriminantAnalysis())])\n",
    "\n",
    "    ## Logistic Regression\n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    ## Support vector machine\n",
    "    svm = Pipeline([('scale', StandardScaler()),\n",
    "                       ('svm', SVC(C = 30))])\n",
    "\n",
    "    ## Random Forest\n",
    "    rf = RandomForestClassifier(max_depth=8, \n",
    "                                n_estimators=500)\n",
    "    \n",
    "    ## Vote\n",
    "    ## complete the VotingClassifier\n",
    "    vote = VotingClassifier([('log_reg', Pipeline([('get_column', FunctionTransformer(get_single_feature)),\n",
    "                                                 ('log_reg', LogisticRegression())])),\n",
    "                             ])\n",
    "    \n",
    "    \n",
    "    ### Fitting the models ###\n",
    "    ada_boost.fit(seeds_tt[features], seeds_tt.y)\n",
    "    knn.fit(seeds_tt[features], seeds_tt.y)\n",
    "    qda.fit(seeds_tt[features], seeds_tt.y)\n",
    "    log_reg.fit(seeds_tt['Aspect_Ration'].values.reshape(-1,1), seeds_tt.y)\n",
    "    svm.fit(seeds_tt[features], seeds_tt.y)\n",
    "    rf.fit(seeds_tt[features], seeds_tt.y)\n",
    "    vote.fit(seeds_tt[features], seeds_tt.y)\n",
    "\n",
    "    \n",
    "    ### Getting predictions ###\n",
    "    ada_pred = ada_boost.predict(seeds_ho[features])\n",
    "    knn_pred = knn.predict(seeds_ho[features])\n",
    "    qda_pred = qda.predict(seeds_ho[features])\n",
    "    log_pred = log_reg.predict(seeds_ho['Aspect_Ration'].values.reshape(-1,1))\n",
    "    svm_pred = svm.predict(seeds_ho[features])\n",
    "    rf_pred = rf.predict(seeds_ho[features])\n",
    "    vote_pred = vote.predict(seeds_ho[features])\n",
    "\n",
    "    \n",
    "    ### Recording Accuracies ###\n",
    "    cv_accs[i,0] = accuracy_score(seeds_ho.y, ada_pred)\n",
    "    cv_accs[i,1] = accuracy_score(seeds_ho.y, knn_pred)\n",
    "    cv_accs[i,2] = accuracy_score(seeds_ho.y, qda_pred)\n",
    "    cv_accs[i,3] = accuracy_score(seeds_ho.y, log_pred)\n",
    "    cv_accs[i,4] = accuracy_score(seeds_ho.y, svm_pred)\n",
    "    cv_accs[i,5] = accuracy_score(seeds_ho.y, rf_pred)\n",
    "    cv_accs[i,6] = accuracy_score(seeds_ho.y, vote_pred)\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89defa0",
   "metadata": {},
   "source": [
    "#### b. \n",
    "\n",
    "Which model had the best average cross-validation accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5ad4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f0b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936430c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0b2957c",
   "metadata": {},
   "source": [
    "##### c. \n",
    "\n",
    "Remember that it is often useful to compare your best model to a simple baseline. In this case the logistic regression model using a single feature is a good baseline we can use. How much does your best model improve upon this baseline? Is your model easier to interpret than the logistic regression model? Could you think of a situation in which we would go with the logistic regression model instead of the one with the best average cross-validation accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77fde1c",
   "metadata": {},
   "source": [
    "##### Write your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e03077f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "680dd863",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "Train the model you chose on the entire training set. Then compute the accuracies on the training set and the test set. Does the model seem to be overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc0777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1716d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb3c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5072aef9",
   "metadata": {},
   "source": [
    "#### 5. Considering other metrics\n",
    "\n",
    "##### a.\n",
    "\n",
    "In this classification problem we only considered accuracy, which was reasonable given the problem as well as the near $50\\%-50\\%$ split of the two pumpkin seed classes.\n",
    "\n",
    "Describe a situation in which you would want to consider a metric other than accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536885fe",
   "metadata": {},
   "source": [
    "##### Write your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfadc2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab4798f8",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396720c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
