{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef78ced",
   "metadata": {},
   "source": [
    "# Fall Problem Session 7\n",
    "## Classifying Pumpkin Seeds I\n",
    "\n",
    "In the next few notebooks you will work to build models to classify types of pumpkin seeds using features engineered from photographs of the seeds. Here we will introduce the data set, perform some exploratory data analysis and build some simple models.\n",
    "\n",
    "The problems in this notebook will cover the content covered in our `Classification` notebooks including:\n",
    "- `Adjustments for Classification`,\n",
    "- `k Nearest Neighbors`,\n",
    "- `The Confusion Matrix` and\n",
    "- `Logistic Regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07fd9e7",
   "metadata": {},
   "source": [
    "#### 1. Load the data\n",
    "\n",
    "##### a.\n",
    "\n",
    "First load the data stored in `Pumpkin_Seeds_Dataset.xlsx` in the `Data` folder.\n",
    "\n",
    "Note you will want to use the `read_excel` function from `pandas`, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html?highlight=read_excel\">https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html?highlight=read_excel</a>. Print a random sample of five rows.\n",
    "\n",
    "Store the data in a variable called `seeds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f682e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc690a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff08a92a",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Create a new column of the `DataFrame` called `y` where `y=1` if `Class=Ürgüp Sivrisi` and `y=0` if `Class=Çerçevelik`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056d5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754b808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c517064b",
   "metadata": {},
   "source": [
    "#### 2. Learn about the data\n",
    "\n",
    "##### a.\n",
    "\n",
    "These data represent various measurements of pumpkin seeds that come from high quality photos of the seeds. The data was provided as supplementary material to <a href=\"https://link.springer.com/article/10.1007/s10722-021-01226-0\">The use of machine learning methods in classification of pumpkin seeds (Cucurbita pepo L.)</a> by Koklu, Sarigil and Ozbek (2021).\n",
    "\n",
    "In this work the researchers demonstrated how various algorithms could be used to predict whether a pumpkin seed was a Ürgüp Sivrisi seed or a Çerçevelik seed. These data were generated by engineering features from special photos of seeds like so:\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"pumpkin_seeds.jpg\" width=\"60%\"></img>\n",
    "\n",
    "As you can see these two seeds can be quite difficult for the human eye to discern, hence the appeal to machine learning algorithms.\n",
    "\n",
    "A PDF of this paper is provided here, <a href=\"pumpkin_seed_paper.pdf\">pumpkin_seed_paper.pdf</a>. Scroll down to Figure 5 and Table 1 and read about the features of this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0d354",
   "metadata": {},
   "source": [
    "#### 3. Train test split\n",
    "\n",
    "##### a.\n",
    "\n",
    "Look at how the data is split between the two classes. Does this appear to be imbalanced data? <i>Recall that we say data is imbalanced if one of the classes has a very small presence in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d540c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39897aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a20a86e",
   "metadata": {},
   "source": [
    "This data set seems pretty well balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce213013",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Make a train test split, set aside $10\\%$ of the data as the test set (note that we are using $10\\%$ because this was the split they used in the paper).\n",
    "\n",
    "Call the training set `seeds_train`, call the test set `seeds_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff4c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b9fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38f62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7cc9c08",
   "metadata": {},
   "source": [
    "#### 4. Exploratory data analysis (EDA)\n",
    "\n",
    "Before building any models you will do some EDA.\n",
    "\n",
    "##### a. \n",
    "\n",
    "One way to try and identify key features for classification algorithms is to plot histograms of the feature values for each of the classes.\n",
    "\n",
    "Below is an example of such a histogram for the `Area` column made using `plt.hist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77598c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note your training set needs to be named seeds_train\n",
    "### in order for this code to work\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "\n",
    "plt.hist(seeds_train.loc[seeds_train.y==0].Area.values,\n",
    "            color='blue',\n",
    "            alpha=.8,\n",
    "            label=\"$y=0$\")\n",
    "\n",
    "plt.hist(seeds_train.loc[seeds_train.y==1].Area.values,\n",
    "            color='red',\n",
    "            alpha=.4,\n",
    "            hatch = '\\\\',\n",
    "            edgecolor='black',\n",
    "            label=\"$y=1$\")\n",
    "\n",
    "plt.xlabel(\"Area\", fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d90fffe",
   "metadata": {},
   "source": [
    "In this plot we can see that the two histograms are right on top of one another, indicating that the two classes of pumpkin seeds tend to have similar areas. This suggests that `Area` may not be a useful variable for discerning the seed class.\n",
    "\n",
    "Use a `for` loop or some comparable method to produce similar histograms for each of the features. Write down the features that look like they may be useful for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe5c49",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa26d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5dc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703091f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59552475",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Now try making a `seaborn` `pairplot` using the variables you identified in part <i>a.</i> as the arguments for `x_vars` and `y_vars`. Use `y` as the argument to `hue`. The main goal with this question is to see if you can identify any pairs of variables that seem to separate the two classes. You will use these plots later in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b893469",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.pairplot(data = ,\n",
    "                x_vars = ,\n",
    "                y_vars = ,\n",
    "                hue = 'y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563c4ce",
   "metadata": {},
   "source": [
    "#### 5. Metric selection\n",
    "\n",
    "In the remainder of this notebook you will make some initial models.\n",
    "\n",
    "##### a.\n",
    "\n",
    "Now that you have read about the data and looked at the split between the two classes what seems like a reasonable performance metric for this problem? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c9cf1",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd093f",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Recalling that `y=1` implies that the seed is of the Ürgüp Sivrisi class and `y=0` implies that the seed is of the Çerçevelik class, what do the following metrics measure in the context of this classification problem:\n",
    "- recall\n",
    "- precision\n",
    "- false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c77821b",
   "metadata": {},
   "source": [
    "##### Write here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c27b5",
   "metadata": {},
   "source": [
    "#### 6. Initial modeling attempts\n",
    "\n",
    "In the remainder of this notebook you will make some initial models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c24fc",
   "metadata": {},
   "source": [
    "##### a.\n",
    "\n",
    "Think of a baseline model for these data. Some common approaches are:\n",
    "- A random coin flip whose probability for heads is the same as the probability of drawing the more present class,\n",
    "- Classifying any observation as the majority class.\n",
    "\n",
    "For whichever baseline you choose project the generalization accuracy of the baseline using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e1d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01fc50c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75bfaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b8d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b0937b",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Fill in the code below to perform 10-fold cross-validation in order to compare logistic regression models regressing `y` on each of the useful features you identified in your EDA above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import what you need here\n",
    "from sklearn.linear_model import \n",
    "from sklearn.metrics import \n",
    "from sklearn.model_selection import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b070c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "\n",
    "\n",
    "kfold = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb5eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a list of your features\n",
    "features = []\n",
    "\n",
    "## this will hold the cv accs\n",
    "log_reg_accs = np.zeros((n_splits, len(features)))\n",
    "\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split():\n",
    "    ## Make sure your training set is called\n",
    "    ## seeds_train\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for :\n",
    "        log_reg = \n",
    "        \n",
    "        log_reg.fit()\n",
    "        \n",
    "        pred = log_reg\n",
    "        \n",
    "        log_reg_accs[i,j] = accuracy_score(seeds_ho.y.values,\n",
    "                                              pred)\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca194a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(log_reg_accs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd2a7a8",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "Compare these models to the logistic regression model that incorporates all of the features you identified with your histogram exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bf81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## will hold the cv split accs\n",
    "full_log_accs = np.zeros(n_splits)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in :\n",
    "    ## Make sure your training set is called\n",
    "    ## seeds_train\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    ## You may need to increase the max_iter, so the algorithm can converge\n",
    "    log_reg = \n",
    "        \n",
    "    log_reg.fit(seeds_tt[features].values,\n",
    "                   seeds_tt.y.values)\n",
    "        \n",
    "    pred = log_reg.predict(seeds_ho[features].values)\n",
    "    \n",
    "    full_log_accs[i] = accuracy_score(seeds_ho.y.values,\n",
    "                                              pred)\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(full_log_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55492f",
   "metadata": {},
   "source": [
    "##### Write any notes you would like here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c90b55",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "Fill in the code to find the optimal $k$ for a $k$ nearest neighbors model encorporating all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import knn\n",
    "from sklearn.neighbors import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7447297",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 26)\n",
    "\n",
    "## make a list of all of the features\n",
    "all_features = \n",
    "\n",
    "## will hold the cv split accs\n",
    "k_all_accs = np.zeros((n_splits, len(ks)))\n",
    "\n",
    "i = 0\n",
    "## Make sure your training set is called\n",
    "## seeds_train\n",
    "for train_index, test_index in kfold.split(seeds_train, seeds_train.y):\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for k in ks:\n",
    "        knn = \n",
    "        \n",
    "        ## fit the model\n",
    "        \n",
    "        \n",
    "        ## get the prediction\n",
    "        pred = \n",
    "        \n",
    "        k_all_accs[i,j] = accuracy_score(seeds_ho.y.values, pred)\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9885bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will plot the avg CV accuracies for you\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "\n",
    "plt.plot(ks, \n",
    "         np.mean(k_all_accs, axis=0),\n",
    "         '-o')\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"$k$\", fontsize=16)\n",
    "plt.ylabel(\"Avg. CV Accuracy\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b1de8",
   "metadata": {},
   "source": [
    "##### e. \n",
    "\n",
    "Now see if you can improve the accuracy by using just the features you chose as a result of your histogram explorations. Did the best accuracy change? Did the optimal value of $k$ change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 26)\n",
    "\n",
    "k_select_accs = np.zeros((n_splits, len(ks)))\n",
    "\n",
    "i = 0\n",
    "## Make sure your training set is called\n",
    "## seeds_train\n",
    "for train_index, test_index in kfold.split(seeds_train, seeds_train.y):\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for k in ks:\n",
    "        knn = KNeighborsClassifier(k)\n",
    "        \n",
    "        \n",
    "        knn.fit()\n",
    "        \n",
    "        pred = knn.predict()\n",
    "        \n",
    "        k_select_accs[i,j] = accuracy_score(seeds_ho.y.values, pred)\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31532103",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "\n",
    "plt.plot(ks, \n",
    "         np.mean(k_select_accs, axis=0),\n",
    "         '-o')\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"$k$\", fontsize=16)\n",
    "plt.ylabel(\"Avg. CV Accuracy\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bbc56c",
   "metadata": {},
   "source": [
    "##### f.\n",
    "\n",
    "As a final check see if you can improve the cross-validation accuracy further by only considering a pair of features from your `pairplot` exploration earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 51)\n",
    "\n",
    "k_final_accs = np.zeros((n_splits, len(ks)))\n",
    "\n",
    "i = 0\n",
    "## Make sure your training set is called\n",
    "## seeds_train\n",
    "for train_index, test_index in kfold.split(seeds_train, seeds_train.y):\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for k in ks:\n",
    "        knn = KNeighborsClassifier(k)\n",
    "        \n",
    "        knn.fit()\n",
    "        \n",
    "        pred = knn.predict()\n",
    "        \n",
    "        k_final_accs[i,j] = accuracy_score(seeds_ho.y.values, pred)\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "\n",
    "plt.plot(ks, \n",
    "         np.mean(k_final_accs, axis=0),\n",
    "         '-o')\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"$k$\", fontsize=16)\n",
    "plt.ylabel(\"Avg. CV Accuracy\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa698eee",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ca040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
