{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875c16fa",
   "metadata": {},
   "source": [
    "# Fall Problem Session 9\n",
    "## Classifying Pumpkin Seeds III\n",
    "\n",
    "In this notebook you continue to work with the pumpkin seed data from <a href=\"https://link.springer.com/article/10.1007/s10722-021-01226-0\">The use of machine learning methods in classification of pumpkin seeds (Cucurbita pepo L.)</a> by Koklu, Sarigil and Ozbek (2021).\n",
    "\n",
    "\n",
    "The problems in this notebook will cover the content covered in some of our `Classification`, `Dimension Reduction` and our `Ensemble Learning` notebooks. In particular we will cover content touched on in:\n",
    "- `Classification/Support Vector Machines`\n",
    "- `Classification/Decision Trees`,\n",
    "- `Ensemble Learning/Random Forests` and\n",
    "- `Dimension Reduction/Principal Components Analysis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing packages you will likely use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf457885",
   "metadata": {},
   "source": [
    "#### 1. Load and prepare the data\n",
    "\n",
    "Run the code below in order to:\n",
    "\n",
    "- Load the data stored in `Pumpkin_Seeds_Dataset.xlsx` in the `Data` folder,\n",
    "- Create a column `y` where `y=1` if `Class=Ürgüp Sivrisi` and `y=0` if `Class=Çerçevelik` and\n",
    "- Make a train test split setting $10\\%$ of the data aside as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the data\n",
    "seeds = pd.read_excel(\"../Data/Pumpkin_Seeds_Dataset.xlsx\")\n",
    "\n",
    "## making a target column, y\n",
    "seeds['y'] = 0\n",
    "\n",
    "seeds.loc[seeds.Class=='Ürgüp Sivrisi', 'y']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907076c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making a stratified train test split\n",
    "seeds_train, seeds_test = train_test_split(seeds.copy(),\n",
    "                                              shuffle=True,\n",
    "                                              random_state=123,\n",
    "                                              test_size=.1,\n",
    "                                              stratify=seeds.y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078109c",
   "metadata": {},
   "source": [
    "#### 2. Refresh your memory\n",
    "\n",
    "If you need to refresh your memory on these data and the problem, you may want to look at a small subset of the data, look back on `Fall Problem Session 7` and `Fall Problem Session 8` and/or browse Figure 5 and Table 1 of this paper, <a href=\"pumpkin_seed_paper.pdf\">pumpkin_seed_paper.pdf</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bcbf77",
   "metadata": {},
   "source": [
    "#### 3. A support vector machine classifier\n",
    "\n",
    "In this problem you will work to build a support vector classifier on these data. Along the way you will get a closer look at iterative versions of the hyperparameter grid search. \n",
    "\n",
    "##### a.\n",
    "\n",
    "Start by importing the support vector classifier from `sklearn`. Note that these data are not close to being linearly separable so we will not want `LinearSVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5806f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import LinearSVC here\n",
    "from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0014c0b9",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "You will now perform hyperparameter tuning on the `C` parameter of the support vector classifier. Fill in the missing pieces of the code below to perform 10-fold cross-validation for different values of `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14022e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the correct kfold class\n",
    "from sklearn.model_selection import \n",
    "\n",
    "## import Pipeline and StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## import accuracy_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this will isolate the feature columns for you\n",
    "features = seeds_train.columns[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the number of CV folds\n",
    "n_splits = \n",
    "\n",
    "## Make the kfold object\n",
    "kfold = \n",
    "\n",
    "## the values of C you will try\n",
    "Cs = [.01, .1, 1, 10, 25, 50, 75, 100, 125, 150]\n",
    "\n",
    "## this will hold the CV accuracies\n",
    "C_accs1 = np.zeros((n_splits, len(Cs)))\n",
    "\n",
    "\n",
    "## the cross-validation loop\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(seeds_train, seeds_train.y):\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    ## loop through all possible values of C\n",
    "    for C in Cs:\n",
    "        ## make the model, fit it and get the prediction \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        pred = \n",
    "        \n",
    "        ## record the accuracy of your prediction on the holdout set\n",
    "        C_accs1[i, j] = accuracy_score(seeds_ho.y, pred)\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f7f3e3",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "Plot the average cross-validation accuracy against the $\\log$ of `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b237d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a figure object\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "## plot the log of C on the horizontal axis,\n",
    "## the avg cv accuracy on the vertical axis\n",
    "plt.plot()\n",
    "\n",
    "## adding labels\n",
    "plt.xlabel(\"$\\log(C)$\", fontsize=16)\n",
    "plt.ylabel(\"Avg. CV Accuracy\", fontsize=16)\n",
    "plt.xticks(np.arange(-2,3,.5),fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30465687",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "A common thing that is done after one grid search is to do another grid search using values from the previous grid search as the endpoints of the grid. This is done to try and better hone in on the optimal value of the hyperparameter.\n",
    "\n",
    "Create a new grid of `C` values using the plot you made in <i>c.</i> to determine the new endpoints. Then run cross-validation a second time. Plot the average accuracies against `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a782dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the values of C you will try\n",
    "Cs = \n",
    "\n",
    "## this will hold the CV accuracies\n",
    "C_accs2 = np.zeros((n_splits, len(Cs)))\n",
    "\n",
    "\n",
    "## the cross-validation loop\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(seeds_train, seeds_train.y):\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    ## looping through your new C values\n",
    "    for C in Cs:\n",
    "       ## make the model, fit it and get the prediction  \n",
    "    \n",
    "        \n",
    "    \n",
    "        pred = \n",
    "\n",
    "        ## record the accuracy of your prediction on the holdout set\n",
    "        C_accs2[i, j] = accuracy_score(seeds_ho.y, pred)\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "## Plot the C values on the horizontal axis\n",
    "## plot the avg CV accuracies on the vertical axis\n",
    "plt.plot()\n",
    "\n",
    "plt.xlabel(\"$C$\", fontsize=16)\n",
    "plt.ylabel(\"Avg. CV Accuracy\", fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5fe43",
   "metadata": {},
   "source": [
    "##### e.\n",
    "\n",
    "What was the optimal value of `C`, what was the average cross-validation accuracy for this value of `C`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359a5f7",
   "metadata": {},
   "source": [
    "##### Write your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf73c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dd1339e",
   "metadata": {},
   "source": [
    "#### 4. Tuning a random forest with `GridSearchCV`\n",
    "\n",
    "In this problem you will tune the `max_depth` and `n_estimators` hyperparameters of a random forest model. First you will use a `for` loop for the cross-validation. Then you will see how much easier your life could be with `GridSearchCV`.\n",
    "\n",
    "##### a. \n",
    "\n",
    "Import `sklearn`'s random forest model for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the random forest classification model\n",
    "from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a2727",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Fill in the code below to find the values of `max_depth` and `n_estimators` with the highest average cross-validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552aa0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## note this will take about 2 minutes to run\n",
    "\n",
    "## the possible max_depth values you'll consider\n",
    "max_depths = range(1, 11)\n",
    "\n",
    "## you'll consider n_estimators = 100, and 500\n",
    "n_trees = [100, 500]\n",
    "\n",
    "\n",
    "## This will record the accuracies for each loop\n",
    "rf_accs = np.zeros((n_splits, len(max_depths), len(n_trees)))\n",
    "\n",
    "\n",
    "i = 0\n",
    "## the cross-validation loop\n",
    "for train_index, test_index in kfold.split(seeds_train, seeds_train.y):\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    ## looping through all possible max_depth values\n",
    "    for max_depth in max_depths:\n",
    "        k = 0\n",
    "        ## looping through all possible n_estimators values\n",
    "        for n_estimators in n_trees:\n",
    "            print(i,j,k)\n",
    "            ## make the random forest model object here\n",
    "            ## set max_samples = int(.8*len(seeds_tt)) and set a random state\n",
    "            \n",
    "            \n",
    "            ## get the prediction on the holdout set\n",
    "            pred = \n",
    "            \n",
    "            ## record the accuracy of the prediction\n",
    "            rf_accs[i,j,k] = accuracy_score(seeds_ho.y,  pred)\n",
    "            k = k + 1\n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ae52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This gives you the values with the best Avg CV Accuracy\n",
    "max_index = np.unravel_index(np.argmax(np.mean(rf_accs, axis=0), axis=None), \n",
    "                                       np.mean(rf_accs, axis=0).shape)\n",
    "\n",
    "\n",
    "print(\"Maximum Depth:\",max_depths[max_index[0]])\n",
    "print(\"Number of trees:\",n_trees[max_index[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3858b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the optimal mean CV Accuracy here here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c8598",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "In this problem you will learn about `GridSearchCV`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html</a>, a handy class from `sklearn` that makes hyperparameter tuning through a grid search and cross-validation quicker to code up than writing out a series of `for` loops.\n",
    "\n",
    "\n",
    "Read through the code chunks below and fill in the missing code to run the same grid search cross-validation you did above with `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae54519",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first import GridSearchCV\n",
    "from sklearn.model_selection import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will also take about two minutes\n",
    "grid_cv = GridSearchCV(, # first put the model object here\n",
    "                          param_grid = {'max_depth':, # place the grid values for max_depth and\n",
    "                                        'n_estimators':}, # and n_estimators here\n",
    "                          scoring = , # put the metric we are trying to optimize here as a string, \"accuracy\"\n",
    "                          cv = ) # put the number of cv splits here\n",
    "\n",
    "## you fit it just like a model, model.fit(features, target)\n",
    "## fit grid_cv here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607b217",
   "metadata": {},
   "source": [
    "Once a `GridSearchCV` is fit you are easily able to find what hyperparameter combinations were best, what the optimal score was as well as get access to the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can find the hyperparameter grid point that\n",
    "## gave the best performance like so\n",
    "## .best_params_\n",
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ef6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can find the best score like so\n",
    "## .best_score_\n",
    "## You try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling best_estimator_ returns the model with the \n",
    "## best avg cv performance after it has been refit on the\n",
    "## entire data set\n",
    "## You try to look at the best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6fa91",
   "metadata": {},
   "source": [
    "The `best_estimator_` is a model with the optimal hyperparameters that has been fit on the entire training set. Try and predict the pumpkin seed class on the training set with the `best_estimator_` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e8db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c0f9c5b",
   "metadata": {},
   "source": [
    "If you want to look at all of the results, you can do that as well with `.cv_results`. See all that entails by running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4be345",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can get all of the results with cv_results_\n",
    "grid_cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d90abab",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "Using either the `best_estimator_` fitted model or a refitted model according to your results from the `for` loop cross-validation find the feature importance scores. Try and refer back to your notes from `Fall Problem Session 7`, how do the scores compare to your initial EDA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08befa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef24ba8",
   "metadata": {},
   "source": [
    "##### Write any notes here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a1e879",
   "metadata": {},
   "source": [
    "In the next notebook you will build a couple of more models on these data and select a final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8853ad39",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a3a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
