{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55fd5a6",
   "metadata": {},
   "source": [
    "# Fall Problem Session 4\n",
    "\n",
    "## Building a Final Vehicle Sales Model\n",
    "\n",
    "This problem session will be our last time working with a non-time series regression task.\n",
    "\n",
    "These problems will touch on material from all of the lecture notebooks in the `Regression` folder.\n",
    "\n",
    "Your overall goal for the notebook is to build the best regression model you can to predict the final selling price of a vehicle using the data in the `car_sales.csv` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36624b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We first load in packages we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbeaf12",
   "metadata": {},
   "source": [
    "#### 1. Load and process the data\n",
    "\n",
    "##### a.\n",
    "\n",
    "First load the `car_sales.csv` data. Then drop the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b91ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af9484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c73a68",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Run the following code to clean and prepare the data.\n",
    "\n",
    "<i>Note: there is nothing new here, all of this code was covered in `Fall Problem Session 2` and `Fall Problem Session 3`</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(text):\n",
    "    return float(text.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning the mileage, engine and max_power columns\n",
    "cars['mileage'] = cars['mileage'].apply(clean_column)\n",
    "cars['engine'] = cars['engine'].apply(clean_column)\n",
    "cars['max_power'] = cars['max_power'].apply(clean_column)\n",
    "\n",
    "## creating the age column\n",
    "cars['age'] = 2020 - cars['year']\n",
    "\n",
    "## performing the log transform on selling_price and km_driven\n",
    "cars['log_sell'] = np.log10(cars['selling_price'])\n",
    "cars['log_km'] = np.log10(cars['km_driven'])\n",
    "\n",
    "## making one-hot encoded variables for transmission, dealer and owner\n",
    "cars['automatic'] = 1\n",
    "cars.loc[cars.transmission=='Manual', 'automatic'] = 0\n",
    "\n",
    "cars[['first_owner', 'second_owner', 'third_owner']] = pd.get_dummies(cars['owner'])[['First Owner', \n",
    "                                                                                      'Second Owner',\n",
    "                                                                                      'Third Owner']]\n",
    "\n",
    "cars['dealer'] = 1\n",
    "cars.loc[cars.seller_type == 'Individual', 'dealer'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180bce95",
   "metadata": {},
   "source": [
    "##### c. \n",
    "\n",
    "Here is a refresher on the columns of this data set.\n",
    "\n",
    "<u>Outcome Variable</u>\n",
    "- `selling_price` or `log_sell` (you will use `log_sell` in your models)\n",
    "\n",
    "<u>Continuous Features</u>\n",
    "- `km_driven` and thus `log_km`\n",
    "- `mileage`\n",
    "- `engine`\n",
    "- `max_power`\n",
    "- `seats`\n",
    "- `age`\n",
    "\n",
    "<u>Categorical Features</u>\n",
    "- `fuel`\n",
    "- `seller_type`\n",
    "- `transmission`\n",
    "- `owner`\n",
    "\n",
    "<u>One-hot Encoded Variables</u>\n",
    "- `automatic`: `1` if `transmission == \"Automatic\"`, `0` otherwise\n",
    "- `dealer`: `1` if `seller_type != \"Individual\"`, `0` otherwise\n",
    "- `first_owner`: `1` if `owner == \"First Owner\"`, `0` otherwise\n",
    "- `second_owner`: `1` if `owner == \"Second Owner\"`, `0` otherwise\n",
    "- `third_owner`: `1` if `owner == \"Third Owner\"`, `0` otherwise\n",
    "\n",
    "\n",
    "You will ignore `torque` because it would require more cleaning than we will spend time on in these problem sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa8d3c",
   "metadata": {},
   "source": [
    "#### d. \n",
    "\n",
    "Make a train test split, set $20\\%$ aside for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf9115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9610d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0979d99c",
   "metadata": {},
   "source": [
    "#### 2. Even more EDA\n",
    "\n",
    "In the past two notebooks you have looked at potential relationships between `log_sell` and:\n",
    "- `mileage`\n",
    "- `log_km`\n",
    "- `age`\n",
    "- `fuel`\n",
    "- `seller_type` or `dealer`\n",
    "- `transmission` or `automatic` and\n",
    "- `onwer` or `first_owner`, `second_owner` and `third_owner`.\n",
    "\n",
    "This leaves three unexplored variables:\n",
    "- `engine`\n",
    "- `max_power`\n",
    "- `seats`\n",
    "\n",
    "##### a.\n",
    "\n",
    "Make some plots and calculate relevant statistics to examine if these three variables are worth including in potential models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e159fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988deaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d4f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2d666ca",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Make a list of continuous variables you plan on considering for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec22bb1",
   "metadata": {},
   "source": [
    "##### Write your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2bed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3de6cb",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "Refer back to `Fall Problem Session 3`, make a list of categorical variables you plan on considering for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4772a32f",
   "metadata": {},
   "source": [
    "##### Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cc04d9",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "A nice feature of many of `seaborn`'s plotting functions is the ability to change the `color` or `hue` of the plotted objects based on the values of a categorical variable.\n",
    "\n",
    "Doing this with `lmplot`, <a href=\"https://seaborn.pydata.org/generated/seaborn.lmplot.html\">https://seaborn.pydata.org/generated/seaborn.lmplot.html</a>, could be helpful when deciding if you want to add an interaction term.\n",
    "\n",
    "Below is an example of how to implement the `hue` argument to investigate if we might want an interaction term between `age` and `transmission` in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=cars_train,\n",
    "              x='age',\n",
    "              y='log_sell',\n",
    "              hue='transmission',\n",
    "              height=6,\n",
    "              aspect=1.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531eeeef",
   "metadata": {},
   "source": [
    "These two lines look roughly parallel indicating that there may not be an interaction between `age` and `transmission`.\n",
    "\n",
    "Spend some time investigating such plots to decide whether any interaction terms are worth adding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0644f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8b8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c585f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd8d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65ade98f",
   "metadata": {},
   "source": [
    "##### e.\n",
    "\n",
    "Make a list of variables that you think <i>might</i> be good for a model predicting `log_sell` including any interactions we may not have made as columns yet. We will use this in the next portion of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa89ad",
   "metadata": {},
   "source": [
    "##### Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c123486",
   "metadata": {},
   "source": [
    "#### 3. Model comparisons\n",
    "\n",
    "In this question we will work through a few different model selection procedures.\n",
    "\n",
    "##### a. \n",
    "\n",
    "First you will try to implement <i>best subsets selection</i>. Remember that this is when you build all possible models from a given set of features and see which one has the lowest possible cross-validation MSE. Use the function `powerset` below to get a list of all possible models you will consider. \n",
    "\n",
    "<i>Note: You will need to make some alterations to the list returned by `powerset` if you chose to consider a categorical feature with more than two categories. For example, you couldn't have a model with just `first_owner` and `second_owner` but not `third_owner` you always have to have all three when building a model to include `owner`.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05366150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was modified from stackexchange user hughdbrown \n",
    "# at this link, \n",
    "# https://stackoverflow.com/questions/1482308/how-to-get-all-subsets-of-a-set-powerset\n",
    "\n",
    "# This returns the power set of a set minus the empty set\n",
    "def powerset(s):\n",
    "    power_set = []\n",
    "    x = len(s)\n",
    "    for i in range(1 << x):\n",
    "        power_set.append([s[j] for j in range(x) if (i & (1 << j))])\n",
    "        \n",
    "    return power_set[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## An example of what power_set returns\n",
    "powerset(['mileage', 'log_km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa26a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a list of the features you want to consider\n",
    "potential_features = []\n",
    "\n",
    "## create your list of models you will consider here using powerset\n",
    "## all_models should be a list of lists of features\n",
    "## for example you may have the list ['age'] in all_models to denote\n",
    "## the model regressing log_sell on age\n",
    "all_models = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15855cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you need to clean potential models here for categorical \n",
    "## variables do so here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa9045",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Fill in the code below to perform 5-fold cross-validation in order to compare all of the models you made above. Here you will make comparisons of the root mean squared error of the predictions of $10^{\\log\\left(\\text{Selling Price}\\right)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import KFold\n",
    "from sklearn.model_selection \n",
    "\n",
    "## import LinearRegression\n",
    "from sklearn.linear_model\n",
    "\n",
    "## import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a holder for all of your MSEs\n",
    "mses = np.zeros()\n",
    "\n",
    "## make the kfold object\n",
    "kfold =\n",
    "\n",
    "## you can use j as a counter for the split\n",
    "j = 0\n",
    "\n",
    "## complete the .split statement\n",
    "for train_index, test_index in kfold:\n",
    "    cars_tt = \n",
    "    cars_ho = \n",
    "    \n",
    "    ## i is a counter for the model number\n",
    "    i = 0\n",
    "    for model in all_models:\n",
    "        ## fit your model using log_sell as the y variable\n",
    "        \n",
    "        \n",
    "        ## get your prediction on the holdout set\n",
    "        ## the .predict statement should go after the \"10,\" but before the \")\"\n",
    "        pred = np.power(10, )\n",
    "        \n",
    "        ## record the mses using selling_price as the true values\n",
    "        mses[i,j]\n",
    "        \n",
    "        ## increase the count accordingly\n",
    "        i = i + 1\n",
    "    ## increase the count accordingly\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acda914",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the minimum root mse\n",
    "np.min(np.mean(np.sqrt(mses), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c9102",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the model that attained that minimum\n",
    "all_models[np.argmin(np.mean(np.sqrt(mses), axis=1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a461de",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "Now attempt to use lasso regression for feature selection on the features:\n",
    "- `mileage`\n",
    "- `max_power`\n",
    "- `age`\n",
    "- `engine`\n",
    "- `log_km`\n",
    "- `seats`\n",
    "- `dealer`\n",
    "- `automatic`\n",
    "- `first_owner`\n",
    "- `second_owner`\n",
    "- `third_owner`.\n",
    "\n",
    "How do the results compare with what you found in <i>b.</i>?\n",
    "\n",
    "<i>Hint: remember to scale your continuous features with `StandardScaler` first.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import StandardScaler\n",
    "from sklearn.preprocessing \n",
    "\n",
    "## import Lasso\n",
    "from sklearn.linear_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will hold your scaled data\n",
    "## after the comma put the number of features you are considering\n",
    "scaled_data = np.zeros((len(cars_train), ))\n",
    "\n",
    "## make the scaler object here\n",
    "scaler = \n",
    "\n",
    "## use .fit_transform to fit the scaler and then scale the relevant data\n",
    "## make sure that you put in the correct number of columns after the second \":\"\n",
    "## in scaled_data[:,:], for example, if you had 5 continuous variables you were scaling\n",
    "## you would put scaled_data[:,:5]\n",
    "scaled_data[:,:6] = \n",
    "\n",
    "## copy over the unscaled one hot encoded columns accordingly\n",
    "\n",
    "## dealer\n",
    "scaled_data[:,] = \n",
    "\n",
    "## automatic\n",
    "scaled_data[:,] = \n",
    "\n",
    "## first_owner\n",
    "scaled_data[:,] = \n",
    "\n",
    "## second_owner\n",
    "scaled_data[:,] = \n",
    "\n",
    "## third_owner\n",
    "scaled_data[:,] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All of the alphas we will loop through for our lasso\n",
    "alphas = [0.00001,0.0001,0.001,0.005,0.0075,0.01,0.015,0.05,0.1,1]\n",
    "\n",
    "## this will hold the coefficients from each lasso\n",
    "coefs = np.zeros((len(alphas), 11))\n",
    "\n",
    "## the loop\n",
    "## note if you are unsure of what enumerate does\n",
    "## https://docs.python.org/3/library/functions.html#enumerate\n",
    "for i,alpha in enumerate(alphas):\n",
    "    ## make the lasso object\n",
    "    lasso = Lasso()\n",
    "    \n",
    "    ## fit the lass object\n",
    "    ## remember that scaled_data are now the features you will use\n",
    "    lasso.fit()\n",
    "    \n",
    "    ## store the coefficients\n",
    "    coefs[i, :] = lasso.coef_\n",
    "\n",
    "## when you are done this will display the\n",
    "## coefficients in a nice dataframe\n",
    "## NOTE: you should check the column order to make sure\n",
    "## they match what you put into scaled_data\n",
    "pd.DataFrame(coefs, \n",
    "                index=[\"alpha = \" + str(alpha) for alpha in alphas],\n",
    "                columns=['mileage', 'max_power',\n",
    "                          'age', 'engine', \n",
    "                          'log_km', 'seats',\n",
    "                          'dealer', 'automatic',\n",
    "                          'first_owner', 'second_owner',\n",
    "                          'third_owner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28824b8",
   "metadata": {},
   "source": [
    "##### Make any notes you would like here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca353b",
   "metadata": {},
   "source": [
    "If you would like you can compare the avg cross-validation RMSE for the model suggested by lasso here to the model from best subsets selection using the results that should still be stored in `mses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00178d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b45f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c67ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0311cda",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "While we have only covered linear regression model types up to this point there are other regression models. One <i>nonparametric</i> approach is to use <i>$k$-nearest neighbors regression</i>.\n",
    "\n",
    "This model works by taking the average value of $y$ for $X$'s $k$ nearest neighbors in the training set, where nearest here means the observations in the training set that are closest to $X$ in terms of some distance measure (like Euclidean distance) and $k$ is chosen prior to fitting the model. This model can be fit using `sklearn`'s `KNeighborsRegressor`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html</a>.\n",
    "\n",
    "Using only continuous features from your best linear regression model fit a $k$-nearest neighbors regression model with $k=5, 10, 15, 20, 25$ and see which one performs best. Then compare this performance to your best linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Place the values of k you will loop through in a list\n",
    "ks = []\n",
    "\n",
    "knn_mses = np.zeros((len(ks), 5))\n",
    "\n",
    "j = 0\n",
    "for train_index, test_index in kfold.split(cars_train):\n",
    "    cars_tt = cars_train.iloc[train_index]\n",
    "    cars_ho = cars_train.iloc[test_index]\n",
    "    \n",
    "    for i,k in enumerate(ks):\n",
    "        ## this creates the knn model with k neighbors\n",
    "        knn = KNeighborsRegressor(k)\n",
    "        \n",
    "        ## this fits the knn model\n",
    "        knn.fit(cars_tt[['max_power', 'age', 'engine', 'log_km', 'seats']],\n",
    "                   cars_tt.log_sell)\n",
    "        \n",
    "        ## this gets the prediction for the knn model of selling_price\n",
    "        pred = np.power(10, knn.predict(cars_ho[['max_power', 'age', 'engine', 'log_km', 'seats']]))\n",
    "        \n",
    "        ## record the mse for this model\n",
    "        knn_mses[i,j] = \n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What was the k value with the lowest avg. cv rmse?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24047ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What was that lowest avg cv rmse?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010afbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare that to the best avg cv rmse from\n",
    "## the linear regression models above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52514aa8",
   "metadata": {},
   "source": [
    "##### Write any notes you would like here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddeee0",
   "metadata": {},
   "source": [
    "##### e.\n",
    "\n",
    "Prior to choosing your final model, reflect on whether any othe features could have been considered when making this model. You may want to examine a few of the vehicle names while answering this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcc9df",
   "metadata": {},
   "source": [
    "##### Write any code or notes you would like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438d432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5231036",
   "metadata": {},
   "source": [
    "#### 4 Examining the test performance\n",
    "\n",
    "##### a. \n",
    "\n",
    "From all of your investigations choose a final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a1e52",
   "metadata": {},
   "source": [
    "##### Write here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf9bd2",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Fit the model you chose on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5b2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6857e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "856f12d3",
   "metadata": {},
   "source": [
    "##### c. \n",
    "\n",
    "Calculate the root mean squared error for the prediction of $10^{\\log\\left(\\text{Selling Price}\\right)}$ on the training set and the test set.\n",
    "\n",
    "<i>Note: if you did any additional cleaning or feature creation, like making interaction terms, you will need to do that to the test set if you have not already.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca729b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c2987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "518b236d",
   "metadata": {},
   "source": [
    "#### 5. (Bonus) Coefficient of determination or $R^2$\n",
    "\n",
    "In this bonus question you will learn about the <i>coefficient of determination, or $R^2$, as well as adjusted $R^2$. This should only be worked through if you still have time after completing all of the above work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3373c8",
   "metadata": {},
   "source": [
    "##### a.\n",
    "\n",
    "While we have focused on the MSE or RMSE of a model another popular metric is the coefficient of determination, otherwise known as $R^2$. Before defining it is important to note the $R$ is <i>different</i> from $r$, the variable we use to denote the sample Pearson correlation, however in simple linear regression the two are related.\n",
    "\n",
    "Recall that the sample variance for $y$ is given by:\n",
    "\n",
    "$$\n",
    "s_y^2 = \\frac{\\sum_{i=1}^n \\left(y_i - \\overline{y} \\right)^2}{n-1},\n",
    "$$\n",
    "\n",
    "where $\\overline{y}$ denotes the sample mean of $y$. The numerator of this fraction is often referred to as the total sum of squares:\n",
    "\n",
    "$$\n",
    "\\text{SST} = \\sum_{i=1}^n \\left(y_i - \\overline{y} \\right)^2.\n",
    "$$\n",
    "\n",
    "It can be shown that:\n",
    "\n",
    "$$\n",
    "\\text{SST} = \\sum_{i=1}^n \\left(\\hat{y}_i - \\overline{y} \\right)^2 + \\sum_{i=1}^n \\left(y_i - \\hat{y}_i \\right)^2 = \\text{SSR} + \\text{SSE},\n",
    "$$\n",
    "\n",
    "where $\\text{SSR}$ stands for regression sum of squares and $\\text{SSE}$ stands for the residual sum of squares. <i>To help remember the abbreviations it is useful to remember that residuals are also called errors.</i>\n",
    "\n",
    "<i>For a proof of this fact it can be helpful to write this out using linear algebra. A proof can also be found at this link <a href=\"https://webspace.maths.qmul.ac.uk/b.bogacka/SM_I_2013_LecturesWeek_8.pdf\">https://webspace.maths.qmul.ac.uk/b.bogacka/SM_I_2013_LecturesWeek_8.pdf</a>.</i>\n",
    "\n",
    "The coefficient of determination, or $R^2$ is defined as:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\text{SSR}}{\\text{SST}},\n",
    "$$\n",
    "\n",
    "and can be interpretted as the proportion of the variance in the variable of interest accounted for by the model. Note that $R^2 \\in [0,1]$  with $R^2=0$ indicating that your model accounts for none of the data's variance and $R^2=1$ meaning that your model accounts for all of the data's variance. Typically you look for the model with the <i>largest</i> $R^2$.\n",
    "\n",
    "Regress `log_sell` on `age` alone using the training data and then calculate $R^2$, you can do this by hand or by using `sklearn`'s `r2_score` metric, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html</a>. Interpret this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you want to use r2_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab811867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af91c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926afc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ba336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ad0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4f63531",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Calculate the Pearson correlation between `log_sell` and `age` using the training set, then square it. What do you notice?\n",
    "\n",
    "<i>Note: what you notice only holds true in the case of simple linear regression.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f165d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "900612a4",
   "metadata": {},
   "source": [
    "#### c.\n",
    "\n",
    "Now fit the linear regression model you settled on above using the training data. Calculate the $R^2$ and interpret it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccb180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39016ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74fadcef",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "One drawback of $R^2$ is that it is <i>non-decreasing</i> with the addition of new features. So by only considering $R^2$ during model selection you will be more likely to spuriously choose models with more features.\n",
    "\n",
    "One way to account for this non-decreasing property is to use what is known as <i>adjusted $R^2$</i> instead, which institutes a penalty dependent on the number of features you use. Adjusted $R^2$ can be calculated using this formula:\n",
    "\n",
    "$$\n",
    "R^2_\\text{adj} = 1 - (1 - R^2)\\frac{n-1}{n-p},\n",
    "$$\n",
    "\n",
    "where $n$ is the total number of observations and $p$ is the number of features used in your model.\n",
    "\n",
    "Compare the adjusted $R^2$ for the models you used in parts 5 <i>a.</i> and <i>c.</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ff7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ae4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d83e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ee09ab4",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739ae30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
