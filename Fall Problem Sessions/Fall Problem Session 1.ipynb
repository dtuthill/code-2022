{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817b85b5",
   "metadata": {},
   "source": [
    "# Fall Problem Session 1\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "The problems contained in this notebook relate to the concepts covered in the `Data Collection` lecture notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ee125",
   "metadata": {},
   "source": [
    "#### 1. Finding data online\n",
    "\n",
    "##### a.\n",
    "\n",
    "Go to Kaggle.com or the UC Irvine Machine Learning Repository and download a data set of your choice. Download then load that data set below using `pandas`. How many observations are in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1809662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ecb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b99680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "add02282",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Your boss would like to examine potential relationships between various company stock prices. They have assigned you the task of getting all of the historical stock data for `AAPL` and `GOOG`. \n",
    "\n",
    "For this task they would like:\n",
    "- Each company to have their own `.csv` file containing the relevant stock data and\n",
    "- The data to go back to the company's initial public offering (IPO), which is the first day the company started trading its stock publicly (for `AAPL` this was December 12, 1980 and for `GOOG` this was August 19, 2004).\n",
    "\n",
    "<i>Hint: You can try competition sites, repositories or just doing a simple web search for such data.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a145f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302541c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf647f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc670f9f",
   "metadata": {},
   "source": [
    "#### 2. Scraping Sites with `BeautifulSoup`\n",
    "\n",
    "You are interested in examining trends in Broadway revenue and attendance over the years. In this problem you will scrape data from <a href=\"https://www.playbill.com\">https://www.playbill.com/grosses</a> on weekly grosses from Broadway shows.\n",
    "\n",
    "##### a. \n",
    "\n",
    "First scrape the:\n",
    "- Show title,\n",
    "- Theatre name,\n",
    "- Gross,\n",
    "- Seats sold and\n",
    "- Percentage of the cap\n",
    "\n",
    "for all the shows found in the table at this link, <a href=\"https://www.playbill.com/grosses\">https://www.playbill.com/grosses</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9186fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28883f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4603c45",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Notice that on <a href=\"https://www.playbill.com/grosses\">https://www.playbill.com/grosses</a> there is an interactive button under the text \"BROADWAY GROSSES WEEK ENDING\" that allows the user to get grosses for any given week. What happens to the url when you select a different week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0021977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575bb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcc266d2",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "Use `BeautifulSoup` to obtain all possible options for the week selector.\n",
    "\n",
    "<i>Hint: the options are stored in a `select` object, you should be able to find out which portion of the HTML code you want to scrape with the web developer tools</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e38d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54706e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1a59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50c55156",
   "metadata": {},
   "source": [
    "##### d. \n",
    "\n",
    "Write a script to record the data you scraped in <i>a.</i> for the 20 most recent weeks. Make sure to add in a small rest between each request you make to the website (You can do that with `time`'s `sleep` function, <a href=\"https://docs.python.org/3/library/time.html#time.sleep\">https://docs.python.org/3/library/time.html#time.sleep</a>).\n",
    "\n",
    "Your end result here should be a `DataFrame` that tracks the date along with all of the other information requested in <i>a.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6273070a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be4d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc7298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ff03373",
   "metadata": {},
   "source": [
    "##### e. \n",
    "\n",
    "Plot the total gross for each week against the date provided by <a href=\"https://www.playbill.com/grosses\">https://www.playbill.com/grosses</a> for the data you just scraped. For example, if the total gross for the week of 2022-07-31 was 10,000,000 there should be a point on your plot at 2022-07-31 and 10,000,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87da3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb08f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124948a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a7702c2",
   "metadata": {},
   "source": [
    "#### 3. Python and APIs\n",
    "\n",
    "In this problem you will work through scraping ER episode ratings on IMDB using a Python wrapper for the IMDB API called `Cinemagoer` (formerly called `IMDBpy`). Here is a link to the documentation for this package, <a href=\"https://buildmedia.readthedocs.org/media/pdf/imdbpy/latest/imdbpy.pdf\">https://buildmedia.readthedocs.org/media/pdf/imdbpy/latest/imdbpy.pdf</a>.\n",
    "\n",
    "##### a.\n",
    "\n",
    "Go to the documentation linked to above and look for installation instructions. Install the `Cinemagoer` package onto your machine, if you do not already have it installed. You can check that the package is installed by running the code chunks given below.\n",
    "\n",
    "<i>Note, only one person in your group needs to have installed the package on their laptop in order to continue. Do not get hung up on the installation step during the problem session</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54031466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6943db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imdb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a01ef",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Creating a `Cinemagoer` object is what allows us to request data from IMDB. Use the Example at the start of chapter 3 of the documentation (page 7) to learn how to create a `Cinemagoer` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71a5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb0272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1404d6af",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "In order to get rating information from each episode of \"ER\" we need its unique identifier, its `Movie id`.\n",
    "\n",
    "We can find that using the `search_movie` function of the `Cinemagoer` class.\n",
    "\n",
    "Search the documentation for how to use `search_movie` to search for `\"ER\" (1994)` using the search term `'simpsons'`. A `list` should be returned. When you find the entry that corresponds to `\"ER\" (1994)` store a string of the id in a variable called `show_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f951c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c59461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76a99d67",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "Search the documentation for `get_movie` to see how we can get \"ER\" result using the `show_id` that we found in the last problem. Store the result in a variable called `ER`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e43b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10f2edd9",
   "metadata": {},
   "source": [
    "##### e. \n",
    "\n",
    "Search the documentation for `update(series, 'episodes')` to see how to return the IMDB data for each episode and have it stored in your `ER` variable.\n",
    "\n",
    "<i>Note: Do not worry if this seems to take a long time, because \"ER\" had a lot of episodes meaning a lot of calls have to be made to the API.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc4084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1de08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "463a0e9a",
   "metadata": {},
   "source": [
    "##### f.\n",
    "\n",
    "What is kind of Python object is returned when you run `ER['episodes']`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c11023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1dd92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "120128bb",
   "metadata": {},
   "source": [
    "##### g.\n",
    "\n",
    "Look at the `keys` for an episode of your choice using `.keys()`, which one seems to contain the IMDB rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69430af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd0953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5566cb49",
   "metadata": {},
   "source": [
    "##### h.\n",
    "\n",
    "Write some python code to store each episode's rating in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd804b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0dbbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e4ba47f",
   "metadata": {},
   "source": [
    "##### i.\n",
    "\n",
    "Use `matplotlib` to plot the ratings over time to see how reception of the show has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074bc49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59fdf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill in the missing code\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.scatter()\n",
    "\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed7536",
   "metadata": {},
   "source": [
    "#### 4. Slightly more advanced `BeautifulSoup`\n",
    "\n",
    "This is a problem that will introduce a new scraping technique that you may need to use in your future quests for data.\n",
    "\n",
    "Your job is to scrape the player names and `BadPass` `LostBall` columns of the \"Play-by-Play\" table at this link, <a href=\"\"https://www.basketball-reference.com/teams/CHI/1998.html\"\">\"https://www.basketball-reference.com/teams/CHI/1998.html\"</a>.\n",
    "\n",
    "##### a.\n",
    "\n",
    "First go to this link and examine the table in question so you know what you want to scrape.\n",
    "\n",
    "##### b.\n",
    "\n",
    "Make a `BeautifulSoup` object of that link's source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b08cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69f483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87a34508",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "Try to use the `find` function to get the code for the \"Play-by-Play\" table. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e8ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b184299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fefc338",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "`BeautifulSoup` is unable to find the specified table. This is because it is stored as an HTML comment. So we have to search the comments to get the table we want, this is because the table is stored in a comment within the source code.\n",
    "\n",
    "To do so we will use `bs4`'s `Comment` object. Try to follow what is found in this stack post, <a href=\"https://stackoverflow.com/questions/33138937/how-to-find-all-comments-with-beautiful-soup\">https://stackoverflow.com/questions/33138937/how-to-find-all-comments-with-beautiful-soup</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Comment\n",
    "from bs4 import Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcef2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40682798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5b84456",
   "metadata": {},
   "source": [
    "##### e.\n",
    "\n",
    "Once you have found the comment that contains the table we want you have to turn that comment into a `BeautifulSoup` object. Do so now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea16ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4f12665",
   "metadata": {},
   "source": [
    "##### f.\n",
    "\n",
    "Now scrape the desired data and store it in a `pandas` `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3c7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b840b3e",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0363c043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
