{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f29b2f",
   "metadata": {},
   "source": [
    "# Fall Problem Session 11\n",
    "## CIFAR-10 I\n",
    "\n",
    "In this notebook you will work on problems that relate to our neural network content. In particular, this material will touch on the following lecture notebooks:\n",
    "- `Lectures/Neural Networks/1. Perceptrons`,\n",
    "- `Lectures/Neural Networks/2. The MNIST Data Set`,\n",
    "- `Lectures/Neural Networks/3. Multilayer Neural Networks` and\n",
    "- `Lectures/Neural Networks/4. keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcab888",
   "metadata": {},
   "source": [
    "#### 1. Load and inspect the data\n",
    "\n",
    "In this notebook you will work to build neural networks to classify the images found in the CIFAR-10 collection. Before building any models you will need to load and get to know the data.\n",
    "\n",
    "##### a. \n",
    "\n",
    "Import `cifar10` from `keras.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787b3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3efbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38be17b2",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Look throught the `keras` documentation on the `cifar10` data to see how to load the training and test data.\n",
    "\n",
    "Documentation: <a href=\"https://keras.io/api/datasets/cifar10/\">https://keras.io/api/datasets/cifar10/</a>\n",
    "\n",
    "<i>Note: The step of loading the data may take a while if this is your first time loading the data.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbcc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this code chunk, you'll use it in a bit.\n",
    "label_dict = {0:'airplane',\n",
    "                 1:'automobile',\n",
    "                 2:'bird',\n",
    "                 3:'cat',\n",
    "                 4:'deer',\n",
    "                 5:'dog',\n",
    "                 6:'frog',\n",
    "                 7:'horse',\n",
    "                 8:'ship',\n",
    "                 9:'truck'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036f341",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "The CIFAR (Canadian Institute for Advanced Research) 10 data are a collection of $60{,}000$ $32\\times 32$ pixelated color images each being an instance of one of the 10 possible classes listed above. Each of the ten classes has $6{,}000$ instances ($5{,}000$ in the training set, $1{,}000$ in the test set). Here is a link to the documentation for this data set, <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">https://www.cs.toronto.edu/~kriz/cifar.html</a>.\n",
    "\n",
    "- Look at the shape of `X_train`. \n",
    "- Print out the first observation of the training set.\n",
    "- Then run the given code chunk to see some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64926bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the shape here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## print out the first observation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e735eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extra code chunk if you need it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b58a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(38401)\n",
    "\n",
    "fig,ax = plt.subplots(5,2,figsize=(14, 30))\n",
    "\n",
    "j = 0\n",
    "for i in np.random.choice(range(len(y_train)), 10):\n",
    "    ax[j//2, j%2].imshow(X_train[i,:,:])\n",
    "    \n",
    "    ax[j//2, j%2].set_title(\"Image of \" + label_dict[y_train[i][0]])\n",
    "    \n",
    "    j = j + 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07670a49",
   "metadata": {},
   "source": [
    "#### 3. Prepare the data\n",
    "\n",
    "We will need to prepare the data before we can build a model.\n",
    "\n",
    "##### a.\n",
    "\n",
    "Just like we did for the grayscale MNIST images you will need to scale the pixels so they range from $0$ to $1$. Each of the RGB pixel values have a minimum value of $0$ and a maximum value of $255$.\n",
    "\n",
    "Scale the data in the code cells provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e36f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c70ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b195776",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "In this notebook you will use a feed forward neural network, that means you will need to reshape the array to be a 2D `numpy` array where each row is an observation and each column is one of the pixel RGB values.\n",
    "\n",
    "Reshape the data in the cells provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9059d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r = \n",
    "X_test_r = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee2cc21",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "This is an instance where cross-validation would take too long for the purposes of the problem session. We will instead use the validation set approach for model comparisons. Make a validation split of the training set. Use $15\\%$ of the data for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521eb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cead7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8744e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "268eb455",
   "metadata": {},
   "source": [
    "#### 4. Your first neural network\n",
    "\n",
    "In this problem you will build your first neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ba06e",
   "metadata": {},
   "source": [
    "##### a.\n",
    "\n",
    "Import all of the `keras` stuff you need to build a feed forward neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afe06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import here\n",
    "from keras import \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## For y when training the network\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "### If you have an earlier version of keras ###\n",
    "# from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13832338",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Fill in the missing code chunks below to build a feed forward neural network with a single hidden layer with $50$ nodes.\n",
    "\n",
    "<i>Note: if this network takes a long time to train on your computer, feel free to make the hidden layer smaller. That will speed up the training steps a little bit.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff1cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create an empty model object here\n",
    "model1 =  \n",
    "\n",
    "## Add the Dense layer with 50 nodes,\n",
    "## remember to specify the activation function and the input_shape\n",
    "model1.add()\n",
    "\n",
    "## Add the Dense output layer, how many nodes should this have?\n",
    "## what should the activation function be?\n",
    "model1.add()\n",
    "\n",
    "\n",
    "## Compile the network here with\n",
    "## the 'rmsprop' optimizer, the 'categorical_crossentropy' loss and\n",
    "## 'accuracy' as the only metric\n",
    "model1.compile(optimizer = ,\n",
    "                 loss = ,\n",
    "                 metrics = )\n",
    "\n",
    "## You'll train the model for 40 epochs\n",
    "n_epochs = 40\n",
    "\n",
    "## fit the model here, don't forget to place the\n",
    "## ys in to_categorical\n",
    "## use a batch_size of 512\n",
    "## don't forget to include the validation_data\n",
    "history1 = model1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2686ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the training and validation accuracies here\n",
    "history_dict1 = history1.history\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict1['accuracy'], \n",
    "            label=\"Training Data\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict1['val_accuracy'], \n",
    "            marker='v',\n",
    "            label=\"Validation Data\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b96f088",
   "metadata": {},
   "source": [
    "#### 5. Additional neural networks\n",
    "\n",
    "In this problem you will make a couple more feed forward networks to try and improve upon the performance of your first network.\n",
    "\n",
    "##### a.\n",
    "\n",
    "Try making another feed forward network with a single layer. Increase the size of the hidden layer, as compared to model 1.\n",
    "\n",
    "Does it outperform model 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2961384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Build your model here\n",
    "## Call your history history2 in order for the plot below to work\n",
    "model2 =  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff922fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the validation accuracies of models 1 and 2 here\n",
    "## Make sure your history variable was called history2, if not you'll need to\n",
    "## change the name here\n",
    "history_dict2 = history2.history\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict1['val_accuracy'], \n",
    "            label=\"Model 1\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict2['val_accuracy'], \n",
    "            marker='v',\n",
    "            label=\"Model 2\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d6b986",
   "metadata": {},
   "source": [
    "##### b. \n",
    "\n",
    "Now try making a feed forward network with two hidden layers. Choose whatever size you would like for those layers. How does this compare to the other two models you have made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d839360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create an empty model object here\n",
    "## Call your history history3 in order for the plot below to work\n",
    "model3 =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d5ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the validation accuracies of all three models here\n",
    "## Make sure your history variable was called history3, if not you'll need to\n",
    "## change the name here\n",
    "history_dict3 = history3.history\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict1['val_accuracy'], \n",
    "            label=\"Model 1\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict2['val_accuracy'], \n",
    "            marker='v',\n",
    "            label=\"Model 2\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict3['val_accuracy'], \n",
    "            marker='x',\n",
    "            label=\"Model 3\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa46f7",
   "metadata": {},
   "source": [
    "#### 6. Trying more processed data\n",
    "\n",
    "Now you will explore if pre-processing the data further will improve the model performance.\n",
    "\n",
    "\n",
    "##### a.\n",
    "\n",
    "Use the function below to convert the original RGB image into grayscale. Then create a neural network for this new version of the data that has the same architecture as one of your networks from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0361836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale(X):\n",
    "    return 0.2989*X[:,:,:,0] + 0.5870*X[:,:,:,1] + 0.1140*X[:,:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7fe613",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use to_grayscale on X_train here\n",
    "X_train_g = \n",
    "\n",
    "## make the grayscale validation split using the same\n",
    "## random_state as above\n",
    "X_tt_g, X_val_g, y_tt_g, y_val_g = train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa467d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create an empty model object here\n",
    "## Make sure your history variable is called history4\n",
    "\n",
    "## Also, be sure to change the input_shape so it matches the\n",
    "## dimensions of the grayscale data\n",
    "model4 =  models.Sequential()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11fd739",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the validation accuracy of the RGB version of the model\n",
    "## and the grayscale version of the model here\n",
    "\n",
    "## Make sure your history variable was called history4, if not you'll need to\n",
    "## change the name here\n",
    "history_dict4 = history4.history\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            label=\"RGB Model\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            marker='v',\n",
    "            label=\"Grayscale Model\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71383316",
   "metadata": {},
   "source": [
    "##### b. \n",
    "\n",
    "Now try running the original RGB image data through PCA that captures $90\\%$ of the original data's variance, then build a neural network (with the same architecture as the network in part <i>a.</i>) on that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import PCA from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab81189",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the PCA object\n",
    "pca = PCA(.9)\n",
    "\n",
    "## Get the PCA data\n",
    "## remember to only fit on tt\n",
    "X_tt_pca = \n",
    "\n",
    "## remember to use only .transform here\n",
    "X_val_pca = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81de175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create an empty model object here\n",
    "## Make sure your history variable was called history5\n",
    "\n",
    "## Also, be sure to change the input_shape so it matches the\n",
    "## dimensions of the PCA transformed data\n",
    "model5 =  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106521dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the validation accuracy of the Non-PCA version of the model\n",
    "## and the PCA version of the model here\n",
    "\n",
    "## Make sure your history variable was called history5, if not you'll need to\n",
    "## change the name here\n",
    "history_dict5 = history5.history\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            label=\"Non-PCA Model\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            , \n",
    "            marker='v',\n",
    "            label=\"PCA Model\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39753b9",
   "metadata": {},
   "source": [
    "#### 7. Saving a model\n",
    "\n",
    "##### a.\n",
    "\n",
    "Choose one of the models you built in this session and retrain it to the optimal number of epochs. Store the model in a variable just called `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74253563",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call your model, model\n",
    "model =  models.Sequential()\n",
    "\n",
    "## fill in the rest here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413eeb63",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Running the code below will save your trained model to a file that can be reloaded at a later time.\n",
    "\n",
    "Save your model, you will return to it in `Fall Problem Session 12`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db10cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### fill in a model name here\n",
    "model_filename = \"\"\n",
    "\n",
    "### This will save the model to file\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0924468",
   "metadata": {},
   "source": [
    "That's all for this notebook. You may have noticed that none of your models are particularly good. This is a difficult classification problem and you will continue working on it in `Fall Problem Session 12`. Perhaps we can improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47afe5d1",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12245a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
