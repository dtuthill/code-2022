{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d8db5c",
   "metadata": {},
   "source": [
    "# Fall Problem Session 12\n",
    "## CIFAR-10 II\n",
    "\n",
    "In this notebook you will continue to create neural networks to classify the images of the CIFAR-10 data, <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">https://www.cs.toronto.edu/~kriz/cifar.html</a>. You will make convolutional neural networks (CNNs) and see if they improve upon the feed forward networks from `Fall Problem Session 11`.\n",
    "\n",
    "In particular, this material will touch on the following lecture notebooks:\n",
    "- `Lectures/Neural Networks/2. The MNIST Data Set`,\n",
    "- `Lectures/Neural Networks/3. Multilayer Neural Networks`,\n",
    "- `Lectures/Neural Networks/4. keras`,\n",
    "- `Lectures/Neural Networks/5. Introduction to Convolutional Neural Networks` and\n",
    "- `Lectures/Neural Networks/7. Loading Pre-Trained Models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d607038",
   "metadata": {},
   "source": [
    "#### 1. Load and prepare the data\n",
    "\n",
    "Load the `cifar10` data from `keras.datasets`, scale the pixel values and make a validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a187a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import cifar10 from keras.datasets\n",
    "\n",
    "\n",
    "\n",
    "## import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e82d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data\n",
    "\n",
    "\n",
    "## scale the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94602b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the validation set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b777fea1",
   "metadata": {},
   "source": [
    "#### 2. A first convolutional neural network\n",
    "\n",
    "In this problem you will make your first CNN. \n",
    "\n",
    "##### a. \n",
    "\n",
    "First import everything you will need from `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import what you need from keras\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76cc685",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Try building a CNN with a single convolutional layer of depth $8$ using a $3\\times 3$ filter followed by a pooling layer using a $2\\times 2$ filter with size $2$ strides.\n",
    "\n",
    "Remember that the `X` data here has a different shape than the `X` for the MNIST data. This should impact what you place in the `input_shape` argument of the first convolutional layer.\n",
    "\n",
    "<i>If training this network seems slow to the point of being unworkable, try changing the depth from $8$ to $4$.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an empty sequential model\n",
    "model1 = \n",
    "\n",
    "## Add the convolutional layer here\n",
    "model1.add()\n",
    "\n",
    "## Add the pooling layer here\n",
    "model1.add()\n",
    "\n",
    "## Add the flatten layer\n",
    "model1.add()\n",
    "\n",
    "## Add the feed forward layer, use 100 nodes\n",
    "model1.add()\n",
    "\n",
    "## Add the output layer\n",
    "model1.add()\n",
    "\n",
    "## Same compile step from notebook 11\n",
    "model1.compile(optimizer = 'rmsprop',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f282c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## fit the model for 25 epochs, this can take a little bit\n",
    "## remember the validation data argument.\n",
    "n_epochs=25\n",
    "history1 = model1.fit()\n",
    "\n",
    "history_dict1 = history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the training set accuracy and the validation set accuracy\n",
    "## against the number of epochs trained\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict1['accuracy'], \n",
    "            label=\"Training Data\")\n",
    "plt.scatter(range(1,n_epochs+1), \n",
    "            history_dict1['val_accuracy'], \n",
    "            marker='v',\n",
    "            label=\"Validation Data\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526a61f",
   "metadata": {},
   "source": [
    "#### 3. A CNN with padding\n",
    "\n",
    "##### a.\n",
    "\n",
    "Add in the `padding='same'` argument to the convolutional layer from the network above. Fit this network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8073fc56",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an empty sequential model\n",
    "model2 = models.Sequential()\n",
    "\n",
    "## Add the convolutional layer here\n",
    "## remember the padding='same' argument\n",
    "model2.add()\n",
    "\n",
    "## Add the pooling layer here\n",
    "model2.add(layers.MaxPooling2D((2,2), strides=2))\n",
    "\n",
    "## Add the flatten layer\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "## Add the feed forward layer, use 100 nodes\n",
    "model2.add(layers.Dense(100, activation='relu'))\n",
    "\n",
    "## Add the output layer\n",
    "model2.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "## Some compile step from notebook 11\n",
    "model2.compile(optimizer = 'rmsprop',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b8d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## fit the model for 25 epochs, this can take a bit\n",
    "n_epochs=25\n",
    "history2 = model2.fit(X_tt, \n",
    "                      to_categorical(y_tt), \n",
    "                      epochs=n_epochs, \n",
    "                      batch_size=512,\n",
    "                      validation_data=(X_val,to_categorical(y_val)))\n",
    "\n",
    "history_dict2 = history2.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf2860a",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Plot the validation accuracy for both models and see if the addition of padding had a noticeable impact on the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e684f17",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "\n",
    "plt.scatter(label=\"No Padding\")\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(marker='v',\n",
    "            label=\"With Padding\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f05dee1",
   "metadata": {},
   "source": [
    "##### Write any thoughts you have here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1792087",
   "metadata": {},
   "source": [
    "#### 4. Adding a dropout layer\n",
    "\n",
    "Sometimes while building convolutional or recurrent neural networks you will add what is known as a <i>dropout</i> layer before the final feed forward layer of the network.\n",
    "\n",
    "A dropout layer will randomly turn off input nodes with a probability that you select when setting up the network. For example a dropout layer with probability $0.25$ will turn each of the input nodes to $0$ with probability $0.25$. \n",
    "\n",
    "This may seem counterintuitive because we will be getting rid of some of the work the previous layers of our network have done. However, neural networks have a ton of parameters, meaning that they tend to overfit on the training data. By randomly turning some nodes to $0$ we lessen the networks ability to overfit, which may in turn improve performance on observations not included in the training set.\n",
    "\n",
    "##### a.\n",
    "\n",
    "For `model3` use your results from above to choose either `model1` or `model2` and then add a dropout layer between  the `.Flatten()` layer and the feed forward `Dense()` layer. Dropout layers can be inserted in `keras` with `layers.Dropout(dropout_probability)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e395918",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an empty sequential model\n",
    "model3 = models.Sequential()\n",
    "\n",
    "## Add the convolutional layer here\n",
    "model3.add()\n",
    "\n",
    "## Add the pooling layer here\n",
    "model3.add(layers.MaxPooling2D((2,2), strides=2))\n",
    "\n",
    "## Add the flatten layer\n",
    "model3.add(layers.Flatten())\n",
    "\n",
    "## Add the dropout layer, set the dropout_probability as you'd like\n",
    "model3.add()\n",
    "\n",
    "## Add the feed forward layer, use 100 nodes\n",
    "model3.add(layers.Dense(100, activation='relu'))\n",
    "\n",
    "## Add the output layer\n",
    "model3.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "## Some compile step from notebook 11\n",
    "model3.compile(optimizer = 'rmsprop',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f3247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## fit the model for 25 epochs, this can take a bit\n",
    "n_epochs=25\n",
    "history3 = model3.fit(X_tt, \n",
    "                      to_categorical(y_tt), \n",
    "                      epochs=n_epochs, \n",
    "                      batch_size=512,\n",
    "                      validation_data=(X_val,to_categorical(y_val)))\n",
    "\n",
    "history_dict3 = history3.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b6d55",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Plot the validation accuracies of the original model and the version with a dropout layer. Does one seem to outperform the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea259d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "\n",
    "plt.scatter(label=\"No Dropout\")\n",
    "\n",
    "\n",
    "plt.scatter(marker='v',\n",
    "            label=\"With Dropout\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c25ed",
   "metadata": {},
   "source": [
    "##### Write any thoughts you have here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe73d5",
   "metadata": {},
   "source": [
    "#### 5. Choose a CNN\n",
    "\n",
    "Choose a CNN from the ones you have tested out in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798ca20",
   "metadata": {},
   "source": [
    "##### Write your model choice down here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55d450",
   "metadata": {},
   "source": [
    "#### 6. Choosing a final model\n",
    "\n",
    "We will now pretend that we are done trying models and want to select a final model for these data.\n",
    "\n",
    "##### a.\n",
    "\n",
    "At the end of `Fall Problem Session 11` you saved your best feed forward neural network model to file. Load this network now using `load_model` from `keras.models`.\n",
    "\n",
    "<i>Note: If you were not able to save a model during `Fall Problem Session 11` you can use the model I saved called `matt_model_fall_pb_sess_11`.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860abd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import load_model here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdadf183",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the model here using load_model\n",
    "ff_model = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045a556",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Compare the performance of the feed forward model and the CNN model on the validation set.\n",
    "\n",
    "\n",
    "<i>Note: If you are using `matt_model_fall_pb_sess_11`, this model was trained using the PCA transformed data. You will need to refit PCA on the training portion of the validation split and then transform the validation data prior to finding the validation set performance for this model. The PCA captured 90% of the original data's variance.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54968088",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing accuracy_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eeb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feed Forward Network below ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b24987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2371a2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e27a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN Network below ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba218250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341a9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85865fb0",
   "metadata": {},
   "source": [
    "#### 7. Test set performance\n",
    "\n",
    "##### a.\n",
    "\n",
    "Retrain your final model on the entire training set. Note that this means you will need to redefine your model and retrain it from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f870cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an empty sequential model\n",
    "final_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit the model for 25 epochs, this can take a bit\n",
    "n_epochs=25\n",
    "history = final_model.fit(X_train, \n",
    "                      to_categorical(y_train), \n",
    "                      epochs=n_epochs, \n",
    "                      batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5bb48",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Find the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a5fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce390d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2344fcec",
   "metadata": {},
   "source": [
    "In this notebook we stuck with very small CNNs in order to keep the training time down as much as possible.\n",
    "\n",
    "You are welcome to build bigger CNNs to see if you can improve upon the performance you have already achieved. You should be prepared, however, for the training time on such networks to be quite long, in comparison to what you did here. Per the documentation, <a href=\"http://www.cs.toronto.edu/~kriz/cifar.html\">http://www.cs.toronto.edu/~kriz/cifar.html</a>, the benchmark model takes over an hour to train, but does attain $82\\%$ test set accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a5446",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f5f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
